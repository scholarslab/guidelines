MLA Guidelines for Evaluating Digital Scholarship (v. 3.0) 
(Copy for comment. Not for public release at this time.) (Draft of Nov 17, 2023) 
Document Status: 
Past: This “Guidelines for Evaluating Digital Scholarship” document was drafted by the MLA Committee on Information Technology (CIT) over two years of the committee’s membership, 2022-2024, at the request of the MLA’s Executive Council for a revision of earlier versions of the guidelines. (The MLA issued version 1 in 2000, and version 2.0 in 2012.) Before drafting the current new revision (version 3.0), the CIT and MLA consulted widely by writing for advice to other humanities professional associations, digital humanities organizations, and other MLA committees.
Present: Currently, during November 2023 to January 12, 2024, the CIT is soliciting commentary and feedback on its draft guidelines revision from the same associations, organizations, and committees it previously reached out to as well as others. Suggestions or commentary would be appreciated either for the document as a whole or any specific parts.
Future: The CIT will submit its draft guidelines to the MLA Executive Council for approval or further suggestions at the council’s February 2024 meeting.
–On behalf of the MLA CIT Committee, Alan Liu (UC Santa Barbara)
Suggested Citation: Modern Language Association, “Guidelines for Evaluating Digital Scholarship.” Version 3.0, Modern Language Association, 2024, https//[URL TBD]/.
Executive Summary
The Modern Language Association’s “Guidelines for Evaluating Digital Scholarship” are designed to help departments and scholars implement effective and fair evaluation procedures for hiring, reappointment, tenure, and promotion. Version 3 of the “Guidelines” expands considerably on earlier iterations in recognition of the increased range of scholars, institutions, activities, outputs, and impact of digital scholarship. Under three general headings – “1. Making Digital Scholarship and Its Evaluation Understandable”; “2. Evaluating Digital Research, Teaching, and Service”; and “3. Additional Guidelines for Faculty and Staff, Departments, Institutions, and Professional Associations” – the guidelines declare the principal recommendations listed below (numbered for reference), each of which expands into detailed implementation recommendations. Recommendations are supplemented by resource boxes holding comparisons to guidelines from other organizations and selected resources.
The MLA Committee on Information Technology, which produced these guidelines, hopes that they will assist departments and institutions in adapting their personnel review criteria and procedures to digital research, teaching, service, and other professional activities today; and assist digital scholars in preparing to be reviewed.
Recommendations
1. Making Digital Scholarship and Its Evaluation Understandable
(1.a) Declare Criteria and Procedures — The evaluation of digital scholars should be based on an explicit declaration of criteria and procedures attuned to the nature of digital work. (Rationale & Implementation)
(1.b) Create Individual Candidate Agreements on Criteria and Procedures — Individual understandings about a digital scholar’s roles, resources, outputs, and evaluation may be negotiated with their departments and institutions. (Rationale & Implementation)
(1.c) Fully Document and Explain Digital Scholarship — Candidates and their departments should take extra care to document and explain digital scholarship for personnel reviews. (Rationale & Implementation)

2. Evaluating Digital Research, Teaching, and Service
– Research –
(2.a) Recognize the Difference of Digital Research — To evaluate digital research fairly, review criteria and procedures should be adapted for new research forms, media, and states. (Rationale & Implementation)
(2.b) Recognize Digital Creative Work — Digital creative writing and art should be evaluated according to criteria related to digital design, media, and form in addition to other creative values. (Rationale & Implementation)
(2.c) Recognize “Evergreen” Research — Digital research includes in-progress, iterative, or “evergreen” outputs that should be counted in personnel reviews. (Rationale & Implementation)
(2.d) Recognize Collaboration — Collaborative digital research should be fairly valued. (Rationale & Implementation)
(2.e) Recognize Public Humanities — Where applicable, digital research should be evaluated for its public humanities value. (Rationale & Implementation)
(2.f) Recognize Digital Standards — Professional standards for digital work should be considered as additional dimensions of research quality. (Rationale & Implementation)
(2.g) Expand the Notion of Peer Review — Non-traditional kinds of external validation for research may be considered as equivalents or supplements to peer review. (See also under 1.c) (Rationale & Implementation)
(2.h) Adapt for Digital Scholarship the Procedures for Seeking Referees — External referees (as well as internal reviewers) who are solicited for personnel cases involving substantial or innovative digital research should include experts familiar with digital scholarship. (Rationale & Implementation)
(2.i) Make Appropriate Use of Metrics and Analytics — Quantitative measures may be employed with care as supplements to the qualitative assessment of digital research. (Rationale & Implementation)
(2.j) Acknowledge Local Institutional Opportunities and Constraints — Digital research should be evaluated in the specific context of resources, services, and support opportunities at a candidate’s institution. (Rationale & Implementation)
– Teaching –
(2.k) Value Digital Instruction — Scholars whose teaching includes substantial or innovative digital materials, forms, media, or methods should be evaluated with attention to the added effort and value represented by digital instruction. (Rationale & Implementation)
– Service –
(2.l) Value Digital Service — Digital scholarship results in additional and new kinds of service that should be recognized in personnel reviews. (Rationale & Implementation)

3. Additional Guidelines for Faculty and Staff, Departments, Institutions, and Professional Associations
– For Faculty & Scholar-Staff –
(3.a) Create a Professional Online Presence — Faculty and scholar-staff should maintain a professional online presence. (Rationale & Implementation)
(3.b) Enable Careers for Scholar-Staff — Staff in “alternative academic,” “research software engineer,” and similar digital scholar-staff positions should ask at time of appointment or reappointment for clarification about institutional support for career development and career progression. (Rationale & Implementation)
(3.c) Make Digital Scholarship Ethical — Digital scholars in the humanities should familiarize themselves with relevant human-subjects, privacy, intellectual-property, and other ethics protocols (and flag efforts made to comply with protocols as an extra factor of quality in their work). (Rationale & Implementation)
– For Departments (and Programs and Centers)–
(3.d) Educate Department Faculty About Digital Scholarship — Departments unfamiliar with current trends in digital scholarship should take concrete steps to introduce their faculty to the area so that they can responsibly hire and review scholars focused on such work. (Rationale & Implementation)
(3.e) Clarify Expectations If a New Hire Is Expected to Start a Program — Departments wishing to launch digital humanities (or similar) programs with the help of a new hire should make that expectation explicit. (Rationale & Implementation)
(3.f) Frame Humanities Digital Scholarship in Relation to Digital Scholarship in Other Disciplines — In presenting the personnel cases of digital scholars to higher-level campus reviewing agencies, departments should both compare and contrast humanities digital scholarship to digital work in other disciplines. (Rationale & Implementation)
– For Institutions (Universities & Colleges) –
(3.g) Encourage Interdisciplinary Understanding of Digital Scholarship — Institutions should take concrete steps to encourage disciplines to discover similarities and differences in digital scholarship. (Rationale & Implementation)
– For Professional Associations, Learned Societies, and Organizations in the Humanities and Digital Humanities –
(3.h) Create Repositories of Resources — Associations, societies, and organizations in the humanities (and digital humanities) should maintain repositories of resources, including templates and examples, to assist in documenting and evaluating digital scholarship. (Rationale & Implementation)
(3.i) Create a Protocol for Citing Collaborative Work — Professional associations, societies, and organizations in the humanities (and digital humanities) should coordinate on developing a shared protocol for citing and crediting collaborative scholarship. (Rationale & Implementation)
(3.j) Conduct Workshops on Personnel Review — Professional associations and organizations should organize activities to assist candidates and chairs in preparing personnel cases involving digital scholarship. (Rationale & Implementation)

Credits & Acknowledgements
Works Cited
Introduction
The Modern Language Association’s “Guidelines for Evaluating Digital Scholarship” are designed to help departments and institutions develop effective and fair evaluation methods for hiring, reappointing, tenuring, and promoting scholars whose work includes substantial or innovative digital scholarship. They also orient individual digital scholars to the criteria and procedures for such evaluation.

The guidelines apply to the evaluation of tenure-line or non-tenure-line faculty (including in creative literature and media) and also scholar-staff in academic-technical positions embedded with departments and other academic units (including “alternative academics” and “research software engineers” [RSEs]). They can be adapted for research universities, small liberal arts colleges, community colleges, and other kinds of higher-education organizations with due consideration for differing institutional situations and resources. For additional context, the guidelines cite related recommendations from other disciplines, organizations, and the international digital scholarship community.
Version 1 of these guidelines appeared in 2000, and version 2 in 2012. A key reason for the present version 3 is that digital scholarship has significantly broadened and deepened. Scholarship here refers to any combination of research, teaching, and service (as well the categories of professional “activity,” “development,” or “citizenship” sometimes included in personnel reviews). Digital here means work that is computationally sourced, curated, processed, modeled, analyzed, mediated, networked, communicated, sustained (through preservation and migration), or otherwise facilitated in ways that add value to, or inflect the nature of, scholarship. Digital scholarship has now evolved to the point that most MLA members (and others the membership are responsible for evaluating) perform activities and produce outputs that do not align well with evaluation methods developed for print-based scholarship. Even more challenging is the case of scholars whose work centers on digital materials, forms, and media, or who focus on areas where what is digital can be both theme and practice (such as the digital humanities, new media studies, platform or software studies, media archaeology, science-technology studies, creative “electronic literature,” and “maker” studies).
To varying degrees, the transformative adoption of the digital has resulted in new literacies (e.g., of code), writing genres (e.g., scholarly blogs), research outputs (e.g., datasets, models, and tools), publication modes (e.g., open-access and open-comment), instructional methods (e.g., project-making courses), professional activities (e.g., “hackathons” and software workshops), and forms of service (e.g., helping redesign a department website or leading colleagues in adapting course policies for new technologies such as artificial intelligence). The intellectual work of knowledge acquisition, understanding, and communication enabled by digital scholarship extends and alters the study of languages and literatures, prompting new textual, intertextual, and contextual questions about the discourse of human beings and, increasingly, also machines. To be fairly rewarded, such digital scholarship requires that evaluation criteria and procedures also be extended and altered. 
To reflect the broadened canvas of digital scholarship today, version 3 of these guidelines has been renamed “Guidelines for Evaluating Digital Scholarship.” (Version 2’s narrower title was “Guidelines for Evaluating Digital Humanities and Digital Media.”) As in earlier iterations, version 3 was produced by the MLA’s Committee on Information Technology (CIT), which studied other relevant guidelines, standards, and publications that emerged in the 13 years since the MLA’s last guidelines. The CIT also consulted other humanities professional associations, digital humanities organizations (including international ones), other MLA committees and ad hoc groups, and individual experts, all of whose suggestions and critiques it gratefully acknowledges. (See Credits & Acknowledgements.)
The 2023 "Guidelines for Evaluating Digital Scholarship" presented below contains three sections: 
1.	“1. Making Digital Scholarship and Its Evaluation Understandable”; 

2.	“2. Evaluating Digital Research, Teaching, and Service”; 

3.	3. Additional Guidelines for Faculty and Staff, Departments, Institutions, and Professional Associations.” 
Each section has principal recommendations in boldface (numbered 1.a to 3.j for reference). Each principal recommendation is explained and followed by one or more specific recommendations in italics for how to best implement it. There are also resource boxes with related guidelines from other organizations and a small selection of references.
1. Making Digital Scholarship and Its Evaluation Understandable
(1.a) Declare Criteria and Procedures —
The evaluation of digital scholars should be based on an explicit declaration of criteria and procedures attuned to the nature of digital work. 
Most higher-education institutions have campus-wide academic personnel policies for the evaluation of scholarship in hiring, reappointment, merit increase, promotion, and tenure cases. Some campuses or departments also provide additional guidance about personnel review through guidelines, workshops, or mentoring. Individual departments may also have bylaws addressing how they handle reviews. Typically, though (and for flexibility), many aspects of personnel review are left implicit as part of institutional custom. But such custom can be confusing to candidates, especially new hires or early career scholars; and custom provides even less guidance on evaluating the increasing numbers of non-tenure-track personnel who have entered the profession, including adjunct lecturers, postdoctoral scholars, and scholar-staff (such as “alternative academic” scholars or “research software engineers” [RSEs]). In addition, the custom of language and literature departments (and the humanities generally) is steeped in print-based traditions such that, for example, “everyone knows you should be writing a book.” This makes it especially challenging for digital scholars engaged in substantial or innovative digital research, teaching, and service to know what will be evaluated, let alone how – especially if their work includes novel kinds of materials, forms, and media. For the same reason, departments and reviewing committees themselves may be perplexed or, worse, divided on the what and how of evaluating digital scholarship.
– Implementation Recommendations –
●	Where existing campus and departmental academic personnel policies do not already do so, departments should create for their members a guidance document on the evaluation of digital scholarship. Such a document, which could take the form of a formal attachment to department bylaws or an informal guidelines sheet or FAQ, should provide explanations of appointment, reappointment, merit increase, promotion, and tenure processes as they apply to digital research, teaching, and service activities and outputs (see section 2 below on digital research, teaching, and service). (Or the document can refer to external explanations such as these MLA guidelines and any related guidelines or resources). 
●	The guidance document should be inclusive of personnel in all ranks and positions. Inclusivity in this context means acknowledging and valuing the scholarship, including digital scholarship, contributed by any tenure-line or non-tenure-line faculty and “alternative academic” or “research software engineer” scholar-staff. This is especially important in departments with collaborative digital research and other initiatives supported not just by faculty colleagues but others in different kinds of positions. (See also 2.d below on collaboration in digital scholarship.) The guidance document might also mention that the criteria it explicates can additionally guide graduate students in their digital research and other work. Being explicit about the criteria for the formal evaluation of digital scholarship has the informal benefit of defining professional ideals for future scholars in training.

●	The guidance document should clarify how evaluation for promotion and tenure works when scholars are hired or reviewed jointly by two departments. In such cases, it is important that the two units coordinate on a tandem guidance document (or paired documents) clarifying how each unit’s expectations and procedures match, differ, or dovetail to create a fair evaluation process for candidates. One way campuses hire digital scholars is through joint appointments in a computer science, information science, or data science department, on the one hand, and a humanities or arts department, on the other (where either the STEM or non-STEM department can be the principal party seeking the hire). Other joint appointment arrangements – including between two humanities departments, a humanities department and a center or program with its own FTE, etc. – are also possible. In such circumstances – and especially when more than a single division on campus is involved – a guidance document or a memorandum of understanding agreed to by both units is crucial. The general principle is that it is unfair to scholars to be hired into multiple units whose faculty have no consensus in advance about how, or even whether, to agree on evaluation criteria and processes. Scholars in joint appointments are especially vulnerable in regard to what kind of research is expected for tenure (e.g., books, articles, or projects) and how service for both their departments can be staggered so as not to double normal commitments (which for digital scholars are often compounded by assignments to multiple campus technology committees).
Other Relevant Professional Association Guidelines: 
  American Historical Association, “Guidelines for the Professional Evaluation of Digital Scholarship by Historians” (2015): “it is advisable that chairs and committee heads specify what will count as scholarly contributions toward tenure and promotion. Departments should review and revise written guidelines that define the expectations of ways that colleagues might use digital resources, tools, and networks in their scholarship.”
  Association for Computers and the Humanities,“ACH Guidelines for Assessment of Digital Scholarship in Tenure and Promotion” (2019): “Expectations about any individual scholar’s tenure and promotion criteria should, as much as possible, be made clear at the time of hiring, reviewed at intermediate stages, and reflect a sincere commitment on the part of both the scholar and the institution to assess the scholarly contribution fairly.”
  Conference on College Composition and Communication, “CCCC Promotion and Tenure Guidelines for Work with Technology” (2015): “It is important that tenure and promotion committees work with departmental hiring committees to ensure that expectations for work with digital media and online teaching, scholarship, and service be communicated to prospective new hires. Further, prospective hires should be informed about whether and how work with digital media and online teaching, research, and service will be considered in the tenure and promotion process.”
Useful Resources: 
[TBD]
(1.b) Create Individual Candidate Agreements on Criteria and Procedures —
Individual understandings about a digital scholar’s roles, resources, outputs, and evaluation may be negotiated with their departments and institutions.
The department bears the responsibility for spelling out what is expected of scholars who engage significantly in digital scholarship (see 1.a above, which recommends that departments create a guidance document). (This is a shift in emphasis in the 2023 guidelines. Like similar documents from other professional associations drawn up during the initial rise of humanities digital scholarship, the 2012 MLA guidelines put the responsibility on individual candidates to negotiate ad hoc arrangements with departments.) Nevertheless, digital scholars who may benefit from additional specification of expectations about their work and the technology support available to undertake it should still ask for agreements in their appointment letters supplementing any general guidance document. (For recommendations about employment contracts, see the Conference on College Composition and Communication’s “Statement of Professional Guidance for New Faculty Members.”  On technology support for digital scholars, including for students, see the MLA’s “Guidelines for Institutional Support of and Access to IT for Faculty Members and Students.”) In addition, at each subsequent review candidates should bring to the notice of their departments any new developments in their work requiring clarification about how that work will be evaluated and supported.
– Implementation Recommendations –
●	During hiring, the department should present to the candidate a general understanding of the criteria and procedures for evaluating digital scholarship. But this understanding can be supplemented with additional, specific information for a candidate contained in the letter of appointment. During later evaluation reviews, departments can as needed create additional memoranda of understanding about evaluation criteria and procedures to take account of changes in a candidate’s digital scholarship.
●	During hiring, scholars recruited jointly by two departments or other units should be presented with the procedures for evaluating digital scholarship by both departments or units, or presented with a tandem guidance document. While the candidate should ask for clarification if none is initially given, it is fundamentally the responsibility of the departments or units to explain how they intend to work together or in parallel in personnel reviews, and whether there are differences in expectations and evaluation criteria for digital scholarship.
Other Relevant Professional Association Guidelines:
  Association for Computers and the Humanities, “ACH Guidelines for Assessment of Digital Scholarship in Tenure and Promotion” (2019): “Candidate responsibilities: Ask for clarification of assessment criteria at the time of hiring; Negotiate roles/responsibilities to distinguish research from service.”
Useful Resources: 
Conference on College Composition and Communication (CCCC). “Statement of Professional Guidance for New Faculty Members.” 2022.
MLA. “Guidelines for Information Technology Access and Support for the Modern Languages.” 2012.
(1.c) Fully Document and Explain Digital Scholarship —
Candidates and their departments should take extra care to document and explain digital scholarship for personnel reviews.
Like other humanities scholars, digital scholars create self-statements and portfolios of research, teaching, and service for personnel reviews. These documents are not just for specialists in their field (other digital scholars in their department or for external referees) but for two concentric circles of non-specialists: firstly, humanities colleagues in other fields in a candidate’s own department and, secondly, reviewing committees, deans’ offices, and other agencies that may include members not only in other fields but also in non-humanities disciplines.
Digital scholars need to put extra effort into explaining their work to both these non-specialist circles. For their department colleagues, they have to explain the nature and value of new digital materials, media, and forms of output while also explaining how these are comparable in quantity, quality, and significance to print-based or print-equivalent humanities scholarship. At the same time, for members of higher-level campus reviewing agencies (including scientists and social scientists), they need to accomplish the above while also explaining how digital work in the humanities is both like and unlike that in other disciplines that increasingly use similar digital means focused on data, modeling, visualization, etc. (For example, humanities digital scholars might need to explain how datasets are meaningful in the humanities when they are often orders of magnitude smaller than datasets in the sciences or social sciences and also frequently riddled with missing or ambiguous data due to historical provenance.) Humanities digital scholars thus benefit from fuller, rather than sparser, documentation and explanation of their work.
The departments of humanities digital scholars should also be fuller rather than sparser in their reports on personnel cases to higher reviewing agencies. They should take the dual approach of emphasizing how humanities digital scholarship participates in a university-wide, interdisciplinary project of knowledge and underscoring how it pursues the humanities’ distinctive mode of knowledge (see also 3.f and 3.g below).
– Implementation Recommendations –
●	Digital scholars should ensure that everything they create includes citation and copyright/licensing metadata visible in the artifact itself without requiring readers to ferret it out in an external or framing digital artifact. Effective documentation of digital scholarship for personnel reviews starts with providing good metadata and explanations in scholarship itself. A surprising number of scholarly websites, course sites, blog posts, reports, datasets, models, and other digital work in the humanities (and elsewhere) lack the elementary metadata that would allow a work to be cited – for example, visible information about a work’s who (author, instructor, collaborators, publisher or equivalent) and when (date of original publication and/or revision). Because the copyright or licensing of digital work is often less clear than for most print artifacts due to the frequent use in the digital scholarly community of open licenses, a work’s whose should also be clarified (i.e., who holds copyright?). The best practice, especially for any digital work without a near-print equivalent, is to include in the work itself a suggested citation. An abstract is also useful for giving readers context. For example, if a dataset is part of a larger project, it should include metadata or an abstract that says so. (Scholars creating datasets may wish to follow the evolving best practice of creating an explanatory “datasheet” as proposed and exemplified in Timnit Gebru, et al., “Datasheets for Datasets”.) Digital scholars should also take advantage of digital identifiers to improve their work’s FAIR qualities of Findability, Accessibility, Interoperability, and Reuseability. Examples of such identifiers include ORCID IDs for authors and collaborators and DOI’s for published or posted works.
●	Documentation for personnel reviews should justify why the candidate and department believe the digital scholarship counts as research, teaching, or service (or a combination), especially for any non-traditional form or media of digital scholarship. This is important because to campus reviewing agencies and even to other members of a candidate’s own department it will not always be clear, for instance, why a dataset, blog post, grant report, tool, code, technical workshop, non-refereed and/or public-facing online article, or any other digital activity or artifact unlike traditional work should be counted as scholarship at all, and under which or all the categories of research, teaching, and service (and/or professional activity) to count it. Special care should thus be taken to explain that a specific kind of digital work can be scholarly output depending on its nature and whether it has a potential audience and impact, even if it does not resemble traditional scholarship in form, media, or “finished,” terminal state. Special care should also be taken to explain the significance of any new work added to continuously evolving but previously reviewed digital projects. (See 2.a - 2.d on these and other special traits of digital work.)
●	Documentation of digital scholarship should include a clear identification of the intended and actual audiences of projects. Many digital projects have not just scholarly audiences but non-academic ones in local, regional, national, or international society. These audiences should be explained to reviewing agencies. (See also 2.e on digital scholarship and public humanities.) 
●	Because some kinds of digital scholarship cannot be externally validated through traditional forms of peer review or external refereeing, candidates and their departments should include in their documentation of digital work any evidence of equivalent or supplementary kinds of external validation. Such evidence may be qualitative – e.g., mentions and comments by scholars and other relevant experts; success at securing funding (with feedback from grant agencies and their reviewers); adoption of digital outputs or tools by others; reviews of projects; etc. Such evidence may also be quantitative in the form of bibliometrics, user analytics, etc. Whether the evidence is qualitative or quantitative, it is important that the candidate and department provide context by explaining, for example, the importance of the fact that a digital work was published in a particular venue or reviewed by a particular journal in the field; or the importance and/or limitations of quantitative measures in humanities fields. Such explanations should be especially attentive to the fact that different disciplines have different assumptions about what counts as external validation. For instance, acceptance of a paper for a conference is among the most prestigious forms of external validation in computer science, whereas it is traditionally far less important in personnel reviews of humanities scholars. (For more on peer reviewing, external referees, and metrics, see 2.g, 2.h, and 2.i under research below.)
●	For pragmatic reasons, the documentation of digital scholarship for personnel reviews should include both natively digital materials (or links to them) and print-like samplers. As emphasized in previous versions of these guidelines and in similar documents from other professional associations and digital humanities organizations, responsible evaluation of digital scholarship requires that reviewers experience works in their native digital medium. The 2012 version of the MLA guidelines included the following recommendation under the heading, “Respect Medium Specificity When Reviewing Work”:

“Since scholarly work is always designed for presentation in a specific medium, evaluative bodies should foreground medium specificity by reviewing faculty members’ work in the medium for which it was produced. For example, born-digital and Web-based projects are often spatial, interactive, iterative, and networked. If possible, they should be viewed in electronic form, not in print or as snapshots of dynamic behavior.”

However, members of reviewing agencies on a campus will not always have the time to engage more than shallowly or haphazardly with digital scholarship in its born-digital forms, especially if there are any hurdles that need to be jumped to access, log into, learn how to use, and interact with digital projects. Some members of reviewing agencies may only look at the landing page of an online project and then quickly shuffle through a few of its parts (or none at all). To ensure that digital scholarship is actually observed more fully, therefore, candidates should prepare portfolios that include both a carefully curated shortlist of links to essential and representative parts of a digital project in situ, and print-like samplers, anthologies, or galleries representing the digital materials (with captions and/or descriptions). For any digital work that is non-linear in form (allowing users to select, jump, or drill down), sampler materials curated in print-like formats have the additional advantage of allowing the candidate to control the narrative of the project.
●	Digital scholars should archive or deposit their digital work prior to personnel reviews. On an ongoing basis, but especially before any personnel review, scholars who produce digital works should take sustainability measures such as ensuring that the Internet Archive has a recent snapshot of their essential open-access online materials, and that their writings, projects, datasets, tools, files, etc. are deposited in an institutional digital repository or other such “TRUST” (Transparency, Responsibility, User focus, Sustainability and Technology) repository. Many institutions host or participate in a digital repository system. Respected, technically full-featured, and free international digital repositories such as the European Union’s Zenodo (which assigns version numbers and DOIs to all deposits, and can be integrated with GitHub to deposit “commits”) are also widely used by scholars in many nations and disciplines, including the humanities (where it is sometimes used not just to deposit but to publish writings). Digital scholars who are being reviewed should check that links to their online resources not only function but are accompanied in their review portfolio by links to archived/deposited versions of the work. This not only safeguards the accessibility of research or other materials (essentially creating what the King’s Digital Lab “Checklist for Digital Outputs Assessment” calls “freeze copies” or “site clones”) but also protects the “paper trail” (or digital trail in this case) for future personnel reviews in which committees may want to look back at previous states of digital scholarship to evaluate candidate progress.
●	In documenting and explaining digital scholarship, digital scholars should describe any special resources, infrastructure, or methods they developed or adapted, and any new collaborative relationships they forged with clients, publics, other departments, colleagues, and students. Candidates should also point out any specific challenges posed by limitations on resources, technologies, or support in the local context of their institution (see also 2.j). These are extra factors in weighing the value of digital scholarship that may not be apparent. Such factors should also be emphasized by departments when they report their evaluation of personnel cases to higher reviewing committees.
●	Digital scholars should in their personnel documents highlight any technical expertise they learned or demonstrated (e.g., Python or R programming or text encoding) and any profession-wide technical standards they applied (e.g., FAIR principles of findability, accessibility, interoperability, and reusability; open-source or open-access principles; sustainability principles); etc. (See also 2.f on such digital standards as a factor in evaluating research.)
●	Digital scholars engaged in substantial or innovative digital scholarship should begin or end their self-statements with a high-level, explicit claim about the added value of the digital in their work – i.e., how digital work meaningfully augments, extends, alters, or otherwise makes a difference for scholarship in the candidate’s field or discipline. (For candidates whose primary field is digital scholarship itself – as in the case of scholars identifying as “digital humanists” or “new media critics” – such a summative statement should identify how their work contributes to the evolution of digital scholarly methods or to the understanding of major intellectual or social issues intertwined with the “digital.”)
Other Relevant Professional Association Guidelines:
  American Historical Association, “Guidelines for the Professional Evaluation of Digital Scholarship by Historians” (2015): “Before initiating a digital project and throughout the course of the project, you should be prepared to explain and document its development and progress and its contributions to scholarship.”
  Association for Computers and the Humanities, “ACH Guidelines for Assessment of Digital Scholarship in Tenure and Promotion” (2019):
 
Useful Resources: 
ALLEA Working Group E-Humanities. Sustainable and FAIR Data Sharing in the Humanities: Recommendations of the ALLEA Working Group E-Humanities. ALLEA, 2020.
Ciula, Arianna. “KDL Checklist for Digital Outputs Assessment.” King’s College, 2019. Zenodo.
GOFAIR. “FAIR Principles.” GO FAIR.
Grootveld, Marjan, and Gültekin Gürdal. “OpenAIRE Guide on How to Find a Trustworthy Repository for Your Data.” 2018. Zenodo.
Lin, Dawei, et al. “The TRUST Principles for Digital Repositories.” Scientific Data, vol. 7, no. 1, May 2020, p. 144. www.nature.com.
2. Evaluating Digital Research, Teaching, and Service
Research
(2.a) Recognize the Difference of Digital Research —
To evaluate digital research fairly, review criteria and procedures should be adapted for new research forms, media, and states.
Digital research adds to print-based or -equivalent scholarship an increasingly varied palette of activities leading to new kinds of output. Examples of activities are inventoried in the TaDiRAH Taxonomy of Digital Research Activities in the Humanities. Examples of outputs include: text corpora, datasets, data models and visualizations, code and critical code studies, tools, taxonomies, GIS maps, social network graphs, creative electronic literature, games, exhibits, websites, blog posts, podcasts, and text or multimedia publications integrated with any of the above (e.g., an article published with a dataset). Digital research is also different from print-oriented work because not only “final” or “in-press” outputs matter. In many cases, digital research produces preliminary, intermediary, and iterative outputs (e.g., grant proposals, datasets, mid-progress reports and blog posts, etc.) each of which can find audiences and have impact. The challenge in evaluating digital research is to fairly account for forms, media, and states that may only partly intersect with or generate print equivalents.
 
Fig. 1: From Luise Borek, et al., TaDIRAH taxonomy 
of Digital Research Activities in the Humanities
– Implementation Recommendations –
●	To prevent elements of digital research from becoming invisible “dark matter” in the evaluation process, candidates and their departments should explicitly identify, agree to count, and document assessable digital components of a research portfolio. “Assessable” here means that whatever its form or state, a research component has an identifiable target audience, dissemination channel, and impact that can be attested either qualitatively (e.g., via comments from internal or external reviewers, grant reviewers, or mentions by other scholars) or quantitatively (e.g., through digital analytics or bibliometrics).
●	As a practical matter, candidates and their departments should agree on how to include in the candidate’s official curriculum vitae (c.v.) or equivalent document a section called “Digital Projects” (or similar label) alongside print-oriented sections for “Books,” “Articles and Chapters,” and “In-Press.” At some institutions, c.v.’s for reviews must follow prescribed formats with rigid categories. Entering digital research properly into the record so that it fits in the research category may thus require negotiation between candidates and their department or institution.
●	Where research activities and outputs can be reviewed under more than a single evaluation category, they should receive proportional credit in each category – including specifically as research even if credited elsewhere. This prevents unfairly shunting digital scholarship aside from the category of research, which in institutions such as research universities is often de facto the highest-value criterion in a review.
●	Digital scholars should include in their research statements, and their departments in their case reports, a section or paragraph assessing holistically the overall contribution of the digital to research. The purpose is to provide a safeguard against seeing digital research only as disjointed parts because scholarly conventions have not yet matured to relate the parts in intuitive scholarly wholes (in the way that the many moving parts of print-based research – including working with library collections, navigating the material and conceptual structure of texts, practicing different levels of interpretation, and knitting together descriptive, narrative, and analytical argument – have over time gelled into “reading,” “writing,” and “the book”).
Other Relevant Professional Association Guidelines: 
  “Report of the MLA Task Force on Evaluating Scholarship for Tenure and Promotion” (2006): “The profession as a whole should develop a more capacious conception of scholarship by rethinking the dominance of the monograph, promoting the scholarly essay, establishing multiple pathways to tenure, and using scholarly portfolios” and “Departments and institutions should recognize the legitimacy of scholarship produced in new media, whether by individuals or in collaboration” (p. 11)
  American Academy of Religion, “Guidelines for Evaluating Digital Scholarship” (2018): “Digital scholarship is an expansive term that includes many types or genres of scholarly digital work. In evaluating such work, it is important to take into consideration the genre or genres with which the digital work is engaging. For the purposes of evaluation and review, we recommend the … list of genres of digital scholarship, adapted from the Journal of American History Digital History Review Guidelines.”
Useful Resources: 
Borek, Luise, et al. TaDiRAH: Taxonomy of Digital Research Activities in the Humanities (version 2.0). 2020.
Rockwell, Geoffrey. “On the Evaluation of Digital Media as Scholarship.” Profession, 2011, pp. 152–68, https://www.jstor.org/stable/41714116.
(2.b) Recognize Digital Creative Work —
Digital creative writing and art should be evaluated according to criteria related to digital design, media, and form in addition to other creative values.
Digital creative work in writing, art, design, code, and data have a rich history accompanying the history of computing. International networks of fiction writers, poets, programmers, critics, and theorists such as those in the Electronic Literature Organization have experimented with interactive fiction, hypertext literature, network writing and art, algorithmic literature, data literature, and other forms of computational and multimedia creative work. Because in personnel reviews many institutions count creative work as equivalent to (or in the same bracket as) research, the criteria and procedures used to evaluate creative writing and art should be adjusted to assess creative digital work in ways that also account for the digital.
– Implementation Recommendations –
●	In addition to evaluating digital creative work according to criteria and procedures used to assess other creative work (e.g., originality, craft, style, and personal or social power as witnessed through external refereeing and book reviews), departments and reviewing committees should also apply criteria and procedures specific to digital values. All the recommendations in section 2 of these guidelines can thus be used with variation in the evaluation of digital creative work. For example, the quality of digital creative writing may additionally be judged according to digital technical and formal design standards (see under 2.f).
●	Digital art or design in visual, video, audio, and other media should be counted alongside, or as part of, digital creative work or other scholarship in departments of language and literature (and nearby fields) that employ or oversee scholars with such expertise. This applies, for example, to scholars whose work includes creative digital printing and painting, “maker” activities in a blend of digital and material media, etc. 
Other Relevant Professional Association Guidelines: 
  [TBD?]
Useful Resources: 
Electronic Literature Directory. Home Page. n. d.
Electronic Literature Knowledge Base (ELMCIP). Home Page. n. d.
Hayles, N. Katherine. “Electronic Literature: What Is It?” Electronic Literature Organization, 2007.
Gould, Amanda Starling. “A Bibliographic Overview of Electronic Literature.” Electronic Literature Directory, 2012.
(2.c) Recognize “Evergreen” Research —
Digital research includes in-progress, iterative, or “evergreen” outputs that should be counted in personnel reviews.
One challenge in evaluating digital scholarship is accounting for the dynamic, iterative nature of many digital projects. Digital research is often produced not just in finalized forms but in periodically or cyclically evolving states, including “evergreen” or “living document” states. Examples include text corpora or datasets that expand, improve, or accrue metadata and documentation; code that progresses or is revised (“refactored”); data models that are rerun with new parameters; websites that grow and deepen; and migrations or reimplementations of any digital work to adapt to changing technological environments or technical standards. When evaluating digital research, reviewers must decide when a project is initially placed in the record for evaluation (the equivalent of “published”) and then how to evaluate renewed work in projects that have previously been evaluated.
– Implementation Recommendations –
●	Candidates and their departments should agree on when in-progress digital research should enter the record for institutional review. Whether self-published or published by others, digital projects at any stage of their development cycle may de facto attain the status of “published” because they are delivered online to audiences in ways that accrue impact. Some important digital projects, indeed, never achieve completion because part of their impact is their ever-evolving nature. Especially for early career scholars, deciding when to claim the de facto status of publication for a digital project is important, and can benefit from mentoring by their departments. Factors include whether a project has persuasively crossed the threshold of the digital equivalent of “published,” and what is best for the candidate’s career development. For example, it may be wisest to hold an in-progress digital project back from the official promotion review record until after it has achieved additional external recognition or until it can make the most difference for the candidate (e.g., in a tenure review).
●	Regardless of when digital research is first officially reviewed, subsequent promotion reviews should allow for assessing the amount and quality of new research effort in a project. It is important for departments and reviewing committees not to undervalue the ongoing research effort, sometimes substantial and innovative, required for many continuing digital projects.
●	To make new effort in existing digital research visible, candidates and their departments should describe qualitatively and/or quantitatively the nature of the new work and explain its significance. This might be done, for example, by creating samples of the new work with a statement about its value, examples of user comments, highlights of user metrics, etc.
Other Relevant Professional Association Guidelines:
  ALLEA (European Federation of Academies of Sciences and Humanities) E-Humanities Working Group, “Recognising Digital Scholarly Outputs in the Humanities” (2023): “New communication technologies, like writing or print, have always influenced how the content is structured, delivered and perceived by the audiences. However, the advent of the digital reconfigures changed once again the way we approach the finiteness of the output, which can be fluid and constantly updated…. Thus, in this perspective scholarly texts are treated like software releases – they are constantly improved and updated to respond to the changing environment…. The paradigm of continual improvement does not refer solely to texts but also to databases and collections. “ [Final quotation and URL to be included when the ALLEA document is finalized. Currently it is undergoing open review.]
  American Academy of Religion, “Guidelines for Evaluating Digital Scholarship” (2018): “digital scholarship is also often open ended. In many instances, the launching of a digital project is the beginning of the work rather than its end, and digital scholarship frequently requires maintenance or regular upgrades.”
  College Art Association and the Society of Architectural Historians, “Guidelines for the Evaluation of Digital Scholarship in Art and Architectural History” (2016): “Process can be essential to the creation of knowledge when, for example, the process demands construction of a database or other tools. Structuring substantial amounts of data and constructing a workable database can take years of research that requires a complex cascade of decisions, discussions, and conceptualizations. These essential activities are worthy of evaluation in their own right. Scholars must document such processes and decisions as the scholarship develops, and evaluating committees must attend to process as a contribution to scholarship.”
Useful Resources
Adema, Janneke. Living Books: Experiments in the Posthumanities. MIT Press, 2021. direct.mit.edu, https://doi.org/10.7551/mitpress/11297.001.0001.
Shanahan, Daniel R. “A Living Document: Reincarnating the Research Article.” Trials, vol. 16, no. 1, Apr. 2015, p. 151. Springer Link, https://doi.org/10.1186/s13063-015-0666-5.
(2.d) Recognize Collaboration —
Collaborative digital research should be fairly valued.
In digital research, collaboration is in many cases not only important but necessary. In its section on “Evaluating Collaboration,” the important 2006 “Report of the MLA Task Force on Evaluating Scholarship for Tenure and Promotion” had recommended with reference to humanities scholarship in general  that “opportunities to collaborate should be welcomed rather than treated with suspicion because of traditional prejudices or the difficulty of assigning credit.” The report continued: “We need to devise a system of evaluation for collaborative work that is appropriate to research in the humanities and that resolves questions of credit in our discipline as in others” (p. 56). With the robust expansion of digital scholarship since that report, the need to improve ways of evaluating collaboration in the humanities has grown even more urgent. One reason is that digital scholars work across disciplines with colleagues in such areas as computer science, information science, media studies, and art. For research involving complex combinations of intellectual, technical, design, communication, and other expertise, the traditional humanities paradigm of a solo scholar writing a publication is often superseded by that of multi-competency development teams. Another reason is that such teams often span institutional levels to include not just faculty colleagues but student research assistants, postdoctoral scholars, “alternative academic” or “research software engineer” (RSE) scholar-staff, librarians, campus information technology staff, and others who must be credited fairly to advance the evaluation of their own careers as professionals. Yet another reason is that the digital humanities and other areas focused on digital scholarship expressly champion ideals of open scholarship, transparent acknowledgement, and intellectual-property sharing as a professional ethos. Important declarations of this ethos bearing on collaboration include Bethany Nowviskie’s “Where Credit Is Due: Preconditions for the Evaluation of Collaborative Digital Scholarship” (2011) and Tanya E. Clement et al.’s “Collaborators’ Bill of Rights” (2021).
– Implementation Recommendations –
●	Candidates undergoing review should credit generously, transparently, and as precisely as possible all contributors to a project, including faculty colleagues, scholar-staff colleagues, librarians, postdoctoral scholars, graduate and undergraduate students, campus technical support staff, and others. Credits are best kept on an ongoing basis as visible metadata in digital projects themselves. At the time of a personnel review, candidates should represent collaboration in their record by crediting collaborators in citations of their work or (in the case of complex credits) via links to full collaboration histories accompanied by a brief summary.
●	Equally, candidates should generously, transparently, and as precisely as possible identify their individual contribution to collaborative research. Because collaboration is understood and valued differently across different disciplines (e.g., on review committees with members spanning the sciences, social sciences, and humanities and arts), it is best to provide information about where a candidate’s impact on a project was shared and also where it was individual. (For some reviewers, it may be important to see individual leadership in a collaborative project.)
●	Departments reviewing candidates engaged in collaborative work (digital or otherwise) should establish a uniform convention for citing co-authors and for crediting collaborators. The department should explain this convention when passing review cases forward to other campus reviewing agencies. By comparison with disciplines where team-based, laboratory, and other group projects and publications are standard, the humanities have few, and often only poorly understood, protocols for crediting collaborative research. In the case of co-authored publications, the relevant protocol for the language and literature fields is stated in the MLA’s “Advice for Authors, Reviewers, Publishers, and Editors of Literary Scholarship” (last revised in 2016) as follows: 

“when names of coauthors are listed alphabetically, they are considered to be equal contributors; if out of alphabetical order, then the first person listed is considered the lead author. Coauthors should explain their roles or describe their contributions in the publication itself or when they submit the publication for evaluation.” 

But there is no uniform protocol in the humanities for other kinds of collaboration. This is especially problematic for collaborative digital projects, which may involve participants who do not fit under the rubrics of “(co)author,” “(co)editor,” or other print-equivalent roles. Until a profession-wide protocol is developed for crediting complex collaborative research according to a contemporary ethos of inclusiveness (see the recommendation in 3.h for such a profession-wide protocol), departments should agree on and share with their faculty and campus reviewing agencies a vocabulary for non-“author” project roles (e.g., using in addition to “author” and “co-author” such terms as “director” and “co-director,” “principal investigator” and “co-PI,” “project manager,” “team director,” “analyst,” “designer,” “research assistant,” etc.). Where attributions cannot easily or fairly be included in the main citation of a research project under an encompassing “et al.,” they should be added in a credit statement appended to or linked from a scholar’s review record.
Other Relevant Professional Association Guidelines: 
  American Historical Association, “Guidelines for the Professional Evaluation of Digital Scholarship by Historians” (2015): “Since digital scholarship often includes collaborations, departments should consider developing protocols for evaluating collaborative work, such as co-authored works, undergraduate research, crowdsourcing, and development of tools.”
  College Art Association and the Society of Architectural Historians, “Guidelines for the Evaluation of Digital Scholarship in Art and Architectural History” (2016): “Collaboration is often essential to the successful execution of digital scholarship. Not unlike traditional models of scholarship, multiple skill sets and bodies of expertise may be required to illuminate new evidence, new patterns, and to develop new interpretations of scholarly material. However, since digital scholarship relies on primary evidence that is in digital form and thus readily accessible to computer analysis, it may benefit particularly from collaborative partnerships. This reflects not only the benefit of comparing different interpretive paradigms, but also the frequent necessity for particular sorts of technical expertise. Although collaborative models for developing digital research may represent a shift from sole-authored research in the humanities, collaboration in no way compromises the intellectual rigor of research and analysis, but may indeed require even more sustained and meticulous attention to the project at hand…. It is the scholar’s responsibility and prerogative to explain the different roles each collaborator played and estimate each collaborator’s contribution. In turn, evaluating committees need to be aware that collaborative work often does not break down into easily determined “percentages” that add up to the final project. Collaborative work is not a puzzle where each person brings a predetermined piece to the final picture; rather, it is a process through which intellectual content is generated within and through the collaboration. As such, collaborative work generally takes more time than single-authored work, rather than less.”
Useful Resources: 
Clement, Tanya E., et al. “Collaborators’ Bill of Rights.” Digital Pedagogy in the Humanities, 2021. Humanities Commons.
Fair Cite. Home Page. Fair Cite, 2012.
Nowviskie, Bethany. “Where Credit Is Due: Preconditions for the Evaluation of Collaborative Digital Scholarship.” Profession, 2011, pp. 169–81.
(2.e) Recognize Public Humanities —
Where applicable, digital research should be evaluated for its public humanities value.
Digital research often occurs through online networked media that can draw from the public for materials and collaboration (e.g., through social media, community engagement, or crowdsourcing) and in return communicate with and provide deliverables to the public. For this reason, digital research is one of the modes of “public humanities” addressed in the MLA Ad Hoc Committee on Valuing the Public Humanities’ ”Guidelines for Evaluating Publicly Engaged Humanities Scholarship in Language and Literature Programs” (2022). As the Ad Hoc Committee observes, “Outcomes of public humanities projects include … the development of archives, podcasts, digital stories, exhibitions, and data sets.” Depending on the nature of a digital project, therefore, public humanities outputs should be weighed in addition to, or in place of, scholarly research outputs in accordance with the Ad Hoc Committee’s recommendations for evaluating public humanities work (and also in awareness of traditions of “community engagement,” “scholar activism,” “action research,” etc.).
– Implementation Recommendations –
●	In assessing digital research with a public humanities dimension (whether or not the research also has a scholarly purpose and audience), candidates and departments should follow the recommendations of the MLA Ad Hoc Committee on Valuing the Public Humanities’ ”Guidelines for Evaluating Publicly Engaged Humanities Scholarship in Language and Literature Programs”. One key recommendation important to evaluating public humanities digital scholarship pertains to peer-reviewing:

“although some projects may be amenable to traditional modes of peer review, and while some may be adaptable to newer forms of peer review, such as those provided by journals like Reviews in Digital Humanities or [the book series] Debates in the Digital Humanities, which have successfully provided peer review for digital public humanities scholarship, many of the more participatory projects of public humanities scholarship are ill-suited to peer review since they require more open forms of review and evaluation. It is thus crucial to separate the assessment of public humanities scholarship from peer review and, instead, to evaluate it through the framework provided here.”

Another key part of the Ad Hoc Committee’s document relevant to digital scholars and reviewers is its section titled “Guiding Questions for Assessing Public Humanities Scholarship.” (The first of the seventeen questions in this section, for example, is: “How does the project contribute to the well-being of the community, beyond its effect on the career of the faculty member developing it, the institution sponsoring it, and the financial interests of the business community?”) Appropriately assessing digital scholarship when it intersects with the public requires addressing these guiding questions.

Also important is the Ad Hoc Committee’s observation that projects addressing or engaging the public may be conducted in discourse that is not necessarily the same as scholarly discourse: “it is … crucial to recognize that the language of the project should also be appropriate to partners with whom project directors are collaborating and the audiences the project team strives to reach.” In other words, the language and tone of public humanities outputs should align with their public goals, rather than only with scholarly discourse norms.
Other Relevant Professional Association Guidelines: 
  Modern Language Association. “Guidelines for Evaluating Publicly Engaged Humanities Scholarship in Language and Literature Programs.” Modern Language Association, 2022.
Useful Resources: 
American Historical Association. “Working Group Issues Tenure, Promotion, and the Publicly Engaged Academic Historian Report.” Perspectives on History: Newsmagazine of the American Historical Association, 2010.
Liu, Alan, et al. Research + Activism Bibliography. 2023. (See esp. sections under “General topics” of “Community & civic engagement“ and "Scholar activism”; and under “Activist methods” of “Digital methods”.) 
(2.f) Recognize Digital Standards —
Professional standards for digital work should be considered as additional dimensions of research quality.
Criteria of research quality commonly mentioned in evaluating humanities scholarship include originality, contribution to the field, scope of argument, rigor of thought, writing quality, and others. In evaluating digital research, however, other professional criteria shared in the interdisciplinary and international digital research community should be considered as additional evidence of quality.
These criteria include technical standards for markup, metadata, taxonomy, physical accessibility, and other aspects of digital work  – e.g., the standards articulated in the Text Encoding Initiative Guidelines (TEI), Encoded Archival Description (EAD), Web Ontology Language (OWL), Web Content Accessibility Guidelines (WCAG), and other protocols.
Relevant criteria also include general standards that have become guiding ideals of digital research – e.g., Open Source and Open Access; FAIR Data Principles (Findable, Accessible, Interoperable, Reusable); CARE Principles for Indigenous Data Governance, Datasheets for Datasets, and digital sustainability (including project life-cycle and data repository strategy).
Also relevant are standards of form and design for the construction and presentation of data, models, tools, interfaces, websites, and other outputs. These include the de facto standards set by technical frameworks of JavaScript libraries for visualization design, graphic design, and UX (user experience) design. Some digital projects also conduct user assessments and testing, which are also marks of research quality.
– Implementation Recommendations –
●	Candidates should identify, document, and explain the value added by efforts to follow technical and other professional standards for digital research. Ideally, this information should be part of the “about” statements of projects themselves. But in addition candidates’ self-statements should point out the relevant standards and principles that their digital work enacts, along with any challenges faced in implementation.
●	In regard to design, candidates may wish to add an explanation of their design philosophy or paradigm. This could be helpful because humanities departments are typically less practiced than those in information-science, media studies, and art in understanding and evaluating information design and visual design. (Where applicable, candidates engaged in creating websites and other presentation interfaces may also wish to refer to any design frameworks they have applied – e.g., Bootstrap, React, or other JavaScript “front-end frameworks” for designing web pages – as a way of demonstrating awareness of contemporary design methods. Similarly, candidates who create data visualizations may wish to cite some of the relevant research literature [e.g., Segel and Heer] or industry-standard advice [e.g., Few] on visualization to indicate awareness of method.)
●	Where digital research includes user assessments or testing, candidates should explain the method, process, and participant groups involved. Such testing may take informal forms (e.g., focus groups) or be systematic (e.g., test groups of users, user surveys, etc.) Because the first audience for personnel reviews is typically a scholar’s humanities or near-humanities department unfamiliar with user testing, the explication should concentrate on main goals and results. But because the second audience for personnel reviews can be a campus-level review committee, dean’s office, or other agency including scientists and social scientists, the explication of testing should include some discussion of how systematic the process was and what level of confidence the scholar has in results.
●	In soliciting external referees for personnel reviews, departments should point out that for digital scholars the use of professional technical, design, and other standards should be considered an additional dimension of research quality. (See also 2.h below on referees.)
Other Relevant Professional Association Guidelines: 
  Association for Computers and the Humanities, “ACH Guidelines for Assessment of Digital Scholarship in Tenure and Promotion” (2019):
“The relationship of design, content, and medium should be documented…. Document technical competence as applicable:
* Knowledge and use of technical standards (TEI, XML, GIS, statistical standards, etc.)
* Solidity of database design (metadata standards, fields etc.)
Interoperability with existing resources (as appropriate)....”

Useful Resources: 
Bradley, Kevin. “Defining Digital Sustainability.” Library Trends, vol. 56, no. 1, 2007, pp. 148–63.
Gebru, Timnit, et al. “Datasheets for Datasets.” ArXiv:1803.09010 [Cs], 2019. arXiv.org,.
Global Indigenous Data Alliance (GIDA). “CARE Principles.” Global Indigenous Data Alliance, 2022.
GOFAIR. “FAIR Principles.” GO FAIR, n. d.
TEI Text Encoding Initiative. Text Encoding Initiative (TEI) Guidelines. 2023.
Data Visualization Design:
* Segel, Edward, and Jeffrey Heer. “Narrative Visualization: Telling Stories with Data.” IEEE Transactions on Visualization and Computer Graphics, vol. 16, no. 6, 2010, pp. 1139–48. November 2010.
* Few, Stephen. “Eenie, Meenie, Minie, Moe: Selecting the Right Graph for Your Message.” Perceptual Edge, 2004.
(2.g) Expand the Notion of Peer Review —
Non-traditional kinds of external validation for research may be considered as equivalents or supplements to peer review. (See also under 1.c)
Peer-reviewed online journals, book series, and other venues for publishing digital research that is not print-like are still relatively few in the humanities. (Examples of exceptions at this time include Research Data Journal for the Humanities and Social Sciences, which documents and publishes peer-reviewed datasets; Journal of Digital Humanities, which publishes peer-reviewed articles in tandem with their datasets; and the Debates in Digital Humanities book series, which publishes parallel print and digital versions of scholarship with additional online materials in the digital edition.) To fairly evaluate scholars with substantial or innovative digital research portfolios, review committees should also look for equivalents or supplements to peer review in forms of external validation that arise elsewhere in digital research, including not just at final but also interim points whenever research receives significant feedback. An example is a substantial grant proposal or grant report that is reviewed by referees and has been posted on a funding agency’s website or has been self-published by candidates on their own websites. External feedback by reviewers and others on such an artifact may be considered a near equivalent of a peer review. Another example is a chapter included in an in-progress volume in the Debates in the Digital Humanities book series from U. Minnesota Press, which solicits peer-reviewing from other authors before the volume as a whole is later sent out for traditional peer refereeing. In this case, peer-review of a chapter is not an equivalent but a supplement to peer-reviewed external validation. Yet another example is any dissemination of digital research (e.g., essays, datasets, models, visualizations, scholarly blog posts, writing drafts, slides or recordings of talks, etc.) that attracts substantial reader feedback through comments or annotations in the online platform publishing that research (as occurs on the Manifold book publishing platform) or through discussion forums and social media. And one more example is any distribution of code in GitHub repositories that attracts significant “pulls,” “clones,” “forks,” and other active engagement. Similar to a review of a candidate’s book, all these cases can serve as supplements to the peer reviewing of research.
– Implementation Recommendations –
●	Digital scholars should present evidence of other forms of external validation of their research as equivalents or supplements to peer-reviewing. In addition, candidates should provide context by explaining why some forms of external validation are authoritative while others may be less so but contribute to the total picture.
●	Departments should take into consideration (and explain to higher reviewing agencies) the overall strength of external validation of a candidate’s digital research, whether in the form of traditional peer review or non-traditional equivalents or supplements.
Other Relevant Professional Association Guidelines: 
  College Art Association and the Society of Architectural Historians, “Guidelines for the Evaluation of Digital Scholarship in Art and Architectural History” (2016), 7-8: 

“Opportunities for peer review of digital works exist outside the pathways of review for traditional publications. External peer review for digital scholarship can take place at multiple stages of production and publication.
* Grant applications constitute the first stage of peer review. External funding is critical to the realization of many digital projects, and funding is highly competitive. Applications require that scholars secure multiple letters of support for each project. Letters and application materials are reviewed by experts who frequently provide written feedback.
* Collaboration constitutes another form of peer review, as many digital projects bring together a diverse array of experts as partners and stakeholders. Whether they are discipline-specific scholars or technical advisors, experts provide assessment and evaluation as continuous feedback necessary to collaborative projects.
* Peer review may occur as an iterative and ongoing process because of the fluid workflow of digital publications. For example, a website’s information design or metadata structure might be reviewed by appropriate experts early in the process while some elements of content might be reviewed toward a project’s completion.
* Selection of digital projects for deposit into a preservation repository can be another site of external peer review. In addition to e-journals, digital projects and extensions may be accepted for institutional libraries or other important, accessible scholarly and public history sites because they are judged to be of long-term scholarly value. The librarians and scholars in the institution accepting digital materials provide peer review in this context.”
Useful Resources: 
Bates, David, et al. Peer Review and Evaluation of Digital Resources for the Arts and Humanities Final Report. School of Advanced Study, University of London, 2006.
Nowviskie, Bethany. “Where Credit Is Due: Preconditions for the Evaluation of Collaborative Digital Scholarship.” Profession, 2011, pp. 169–81. (See p. 172 on peer review.)
(2.h) Adapt for Digital Scholarship the Procedures for Seeking Referees —
External referees (as well as internal reviewers) who are solicited for personnel cases involving substantial or innovative digital research should include experts familiar with digital scholarship.
The special features of digital research – e.g., its non-print-like, “evergreen,” collaborative, public-humanities, or technical forms – mean that traditional conventions for the refereeing personnel cases should be adjusted to evaluate digital scholars fairly.
– Implementation Recommendations –
●	In seeking external referees for personnel reviews of digital scholars, departments should solicit at least some experts qualified to judge digital work. However, experts from outside the humanities should be chosen with care. Referees who are both domain experts in a candidate’s field and fluent in technically advanced digital scholarship will grow more numerous over time in humanities disciplines. But except in fields like the digital humanities where much of the referee pool focuses both thematically and technically on the digital, at present it is more realistic for departments to expect to recruit only some external referees who can be both domain and digital experts. Depending on the proportion and nature of the digital research to be reviewed, departments may thus need to add among external referees at least one or more technically qualified experts from outside the candidate’s field. However, it is important that departments be judicious in soliciting referees from outside the humanities (e.g., database or design experts). It can be unfair to candidates to solicit experts from engineering, science, social science, design, and other disciplines if they are unfamiliar with the goals, standards, and intellectual traditions of humanities research. Where there is a risk of such an epistemic mismatch, departments should take care to provide ample guidance for all experts in their solicitation letters (which for equity at many institutions must be the same for all referees or can only be varied from a template by approval of a campus agency).
●	Fair evaluation of digital research requires that departments and institutions be prepared to solicit qualified external referees from any institution at any rank regardless of perceived prestige. Because of the rapid and relatively recent advance of digital scholarship in the humanities, there may be few senior scholars from leading universities who are qualified to referee a digital scholar’s particular research. Departments should thus be willing to include as external referees excellent, qualified reviewers known in the digital research community no matter where they are situated or what rank they hold (including early career scholars or non-scholars who are leaders in new digital forms and media.) Departments should explain their choice of referees in presenting personnel cases to higher campus reviewing agencies. In general, the following recommendation of the “Report of the MLA Task Force on Evaluating Scholarship for Tenure and Promotion” (2006) applies with special relevance to digital scholarship: 

“Departments should solicit letters from the most knowledgeable reviewers in a candidate's field, regardless of the perceived status of the reviewers' institutions. Some college and university guidelines urge department heads to seek reviewers exclusively from colleges and universities viewed as more prestigious than their own, even though there may be no reason to believe that the most knowledgeable reviewers will come from those institutions. Specialists in some fields, particularly emerging fields, may be affiliated with all types of institutions, and it is the job of the department head or the departmental committee that prepares the tenure dossier to explain to deans and provosts why a candidate's referees are qualified to conduct a tenure review even when they do not come from institutions that equal the perceived prestige of the candidate’s own.” (p. 54)
●	Departments should ballast external refereeing with internal reviewing of the digital component of research. Ideally, departments should not take a hands-off approach to evaluating the digital in digital research by leaving it to the candidate to describe it and then leaving it only to external referees to assess it. In departments that formally or informally assign internal reviewers, it is valuable for at least one internal reviewer to be tasked with systematically evaluating the digital aspects of a candidate’s research. Where no qualified internal reviewers exist in a department, they may be solicited from other departments. Internal reviewing of the digital component of a digital scholar’s research not only helps a department more fully appreciate a candidate’s work, but also allows it better to mentor the candidate. (For reasons of equity, it is important that internal reviewers be assigned only if all candidates, and not just digital scholars, are assigned internal reviewers.)
Other Relevant Professional Association Guidelines: 
 College Art Association and the Society of Architectural Historians, “Guidelines for the Evaluation of Digital Scholarship in Art and Architectural History” (2016), 7-8: “Include digital specialists as part of the evaluation process. If digital scholarship is a requirement for employment or accepted as part of a scholar’s portfolio, that work must be evaluated by an expert who understands the digital contribution. This may take the form of outside peer review and/or, ideally, a member of the evaluating committee with particular expertise.”
  American Academy of Religion. “Guidelines for Evaluating Digital Scholarship” (2018): “Every reasonable effort should be made to identify and select external evaluators who are qualified to review the technological and design aspects of the scholarship (e.g., appropriateness of the medium to the project; choice of database, programming language, and web application framework; quality of back-end and front-end design and build; digital continuity; documentation).”
Useful Resources: 
Stanton, Domna C., et al. “Report of the MLA Task Force on Evaluating Scholarship for Tenure and Promotion.” Profession, 2007, pp. 9–71.
(2.i) Make Appropriate Use of Metrics and Analytics —
Quantitative measures may be employed with care as supplements to the qualitative assessment of digital research. 
The increasing use of bibliometric and other quantitative measures to assess research has been a cause of concern even in the sciences. The “Leiden Manifesto” (Hicks et al., 2015), which challenged the primacy of h-index scores and other metrics, carefully weighs the pros and cons of quantitative impact assessment as follows (in the first of its ten principles):
“Quantitative metrics can challenge bias tendencies in peer review and facilitate deliberation. This should strengthen peer review, because making judgements about colleagues is difficult without a range of relevant information. However, assessors must not be tempted to cede decision-making to the numbers. Indicators must not substitute for informed judgment. Everyone retains responsibility for their assessments.”
Even more so in the humanities, quantitative measures for assessing the significance of research must be used with judgment because relevant metrics can be sparse or unreliable. Reasons include the unique nature and rhythm of humanities research (e.g., slowly paced books instead of frequent preprints, conference proceedings, and articles), humanities authoring practices (e.g., relatively few publications with large numbers of co-authors), general inattention to metrics in the humanities, and the comparative lack of humanities publication platforms, venues, and archives that integrate with or display metrics indices. New forms of humanities digital research, however, often circulate in online networked environments that not only make counting citations easier but generate faux-citations such as in-bound links, pull requests of code, etc. And humanities digital research can also generate other kinds of analytics (“altmetrics”), including usage analytics, comment counts, social media mentions, etc. Even so, conventions about how to understand and trust such analytics in the digital humanities, let alone in the humanities generally, have not yet evolved in standardized ways. It is prudent, therefore, to treat quantitative measures in the humanities as supplemental to qualitative assessments of of research. As the King’s Digital Lab’s “Checklist for Digital Outputs Assessment” (Ciula, 2019) recommends about usage analytics:
“Information on data usage provided with contextual narrative for a submission of a digital output are an indicator of the attention paid to monitor use; they are useful to demonstrate how the output is relevant for its intended (or additional pool of) users and to assess its reach when relevant (especially for impact case studies). However, “levels of usage should not be viewed as a key indicator of the scholarly value, or even impact, of a resource”.... Usage reports (where relevant or possible), on the other hand, can be useful to indicate high engagement with the output, wide-spread recognition in the scholarly or other relevant communities and international audience….
– Implementation Recommendations –
●	Candidates and departments should use quantitative bibliometrics, analytics, and related “altmetric” measures to supplement the assessment of research significance. But the lack of such metrics, whether systematically or anecdotally gathered, should not be interpreted as meaningful. This is due to the lack in the humanities of shared expectations and practices of metrics, and also the lack of trusted indices of metrics as they apply to the humanities.)
Other Relevant Professional Association Guidelines: 
  American Academy of Religion. “Guidelines for Evaluating Digital Scholarship.” 2018, https://aarweb.org/AARMBR/AARMBR/About-AAR-/Board-of-Directors-/Board-Resolutions-/Guidelines-for-Evaluating-Digital-Scholarship.aspx: 
“Digital scholarship often has metrics that demonstrate the type of engagement they have with audiences. For many projects, instruments such as page views, downloads, plays, number of users, engagement, code or data reuse, as well as other alternative metrics can be used as evidence of its impact. For other types of digital projects, influence can be established through the development of new work based on its technologies and/or design. Assessment should be based on both the quality and quantity of public access, scholarly engagement, and audience use since evaluative metrics will not be standardized across digital work. Altogether, data from a project’s standard measuring mechanisms should be clearly explained in order to evaluate how it generates stimulating technical and theoretical contributions to scholarship.
However, these metrics should not be relied upon as a sole indicator of a work’s importance. Just as book sales are not necessarily indicative of the importance of a scholarly work for the development of the field, a high-quality work of digital scholarship may have low use metrics. In addition, as with all humanities scholarship, the importance of a particular work in the scholarly ecosystem often increases over time and is not easily seen in data that privileges current popularity. As such, we caution against the use of metrics as a shorthand for the value or impact of digital scholarly work, recommending instead that the primary mode of evaluation for digital scholarship be qualitative, and that use metrics be considered as providing a supplemental indicator of the current reach of the work.”
Useful Resources: 
Broadberry, Laura. “How to Use Altmetrics to Showcase Engagement Efforts for Promotion and Tenure.” Altmetric, 2016.
Ciula, Arianna. “Checklist for Digital Outputs Assessment.” King’s College, 2019. Zenodo, Zenodo. (See p. I on “Usage and analytics.”)
Hicks, Diana, et al. “The Leiden Manifesto for Research Metrics.” Nature, vol. 520, no. 7548, 2015, pp. 429–31. www.nature.com.
Priem, J., et al. “Altmetrics: A Manifesto.” Altmetrics, 2010.
(2.j) Acknowledge Local Institutional Opportunities and Constraints —
Digital research should be evaluated in the specific context of resources, services, and support opportunities at a candidate’s institution.
Scholars in languages and literatures work in a wide spectrum of higher education institutions ranging across the Carnegie scheme (Carnegie Classification of Institutions of Higher Education) and similar frameworks of tertiary education. Some institutions are superbly resourced in faculty, programs, library infrastructure and staff, subscriptions to databases and information technology services, technology support, digital humanities centers or labs, and other resources propelling digital research. Others may have only isolated pockets of faculty, staff, resources, and support in these areas – meaning, for example, that a regional university, small liberal arts college, or community college may not be able to offer their faculty and other digital researchers a stake in the game at the same level. When evaluating digital scholarship, therefore, it is important that there be a way to recognize the local context of opportunities and limitations.
– Implementation Recommendations  –
●	Candidates at well-resourced institutions may wish in their self-statements to describe how they have drawn on relevant institutional resources and support. This is evidence of taking advantage of resources and seeking to learn from (or collaborate with) colleagues and staff across campus. 
●	Candidates at differently resourced institutions should generously acknowledge the technological means and support they have drawn on, but may also wish to describe how specific constraints have influenced research. Significant constraints include the lack of schools or departments in fields adjacent to digital research such as information science or design; inadequate funding for research assistants; inability to access databases (and/or licenses for APIs and other enhanced services for data-scraping from databases); lack of institutional subscriptions to collaborative editing, design, and similar online cloud-based production tools; etc.
Other Relevant Professional Association Guidelines: 
  Conference on College Composition and Communication, “CCCC Promotion and Tenure Guidelines for Work with Technology” (2015): “the candidate’s work be evaluated with respect to local conditions on campus. For example, early adopters of a particular technology on a campus generally face more obstacles than those who come later. Similarly, on campuses where support for technology is limited, individuals who work with digital media may gain experience through challenges with implementation and troubleshooting that benefit colleagues later.”
Useful Resources: 
Risam, Roopika. “Stewarding Place: Digital Humanities at the Regional Comprehensive University.” People, Practice, Power: Digital Humanities Outside the Center, Debates in the Digital Humanities, U. Minnesota Press, 2021.
Teaching
(2.k) Value Digital Instruction —
Scholars whose teaching includes substantial or innovative digital materials, forms, media, or methods should be evaluated with attention to the added effort and value represented by digital instruction.
The digital dimension of teaching has grown in importance as instructors create or adapt courses, instructional materials, instructional technologies, pedagogical formats and methods, and modes of evaluating and communicating with students in ways that exceed off-the-shelf solutions in course management systems or routine productivity software (e.g., PowerPoint slides). For this reason, the specifically digital in instruction by candidates who substantially or innovatively use digital methods should be assessed in evaluations of teaching.
– Implementation Recommendations –
●	As part of documenting and explaining digital scholarship (see 1.c), candidates (and their departments in reporting on cases) should present teaching in ways that make visible the additional preparation, curricular or pedagogical innovation, challenges, and ethics issues involved in digital teaching.
        Additional preparation includes, for example, attending workshops on digital pedagogy or researching course designs at other institutions; preparing datasets or corpora for student assignments; creating tutorials, guides, and exercises in digital methods; making or adapting tools, scripts, and “data notebooks” (such as Jupyter notebooks for lesson plans); producing interactive, multimedia, or virtual-reality learning modules; designing one or more new course units (even just a single week of digital materials or methods); inventing new kinds of assignments or course policies (e.g., to accommodate the use of generative-AI chatbots by students); etc. Whether an instructor’s preparation efforts are small and technologically incremental, or sweeping and technologically advanced, the additional work involved in preparing for digital instruction can be considerable.
        Curricular or pedagogical innovations include new or non-traditional humanities course designs and teaching strategies. For example, these might include (for a specific unit or a whole syllabus) courses designed around lab-style workshops; “flipped classroom” courses in which students engage with digitized lectures or interactive lessons before coming to class for discussions or group work; project-building courses (e.g., in which students edit, text-encode, text-analyze, model, visualize, or create an online edition or archive); courses oriented toward new kinds of digital writing assignments (e.g., blog posts, “data stories,” prompt-based writing with generative AI, hypertext writing, Twine stories, etc.); courses that are online or hybrid either by design or out of necessity (due to the nature of the candidate’s institution, students, or emergency situations); and collaborative courses allowing instructors and students at two or more institutions to co-teach and co-learn.
        Challenges include resource limitations (e.g., lack of an institutional license for desired databases or digital tools, or insufficient campus technical support); problems with technology (e.g., networking issues in a department’s classrooms, inadequate access by literature or language instructors to classrooms optimized for technology teamwork); and similar issues experienced by instructors. Equally important are challenges faced by students at a particular institution and the communities it serves (e.g., students at non-residential colleges whose homes often lack adequate computers, software, or network connectivity). In personnel reviews, such challenges are best framed not in the mode of complaint (that should be addressed outside personnel reviews) but of showing how a candidate creatively makes the best of constraints. For example, candidates at lower-resourced institutions or who serve lower-resourced student communities might show how they have innovated workarounds to problems.
        Ethics issues faced by instructors engaged in substantial or innovative digital teaching include those caused by the fact that online networked instruction exits the “sandbox” of academic coursework to make contact with other social, political, and economic sectors of digital culture. Concerns thus arise over privacy (as regulated in the U.S., for example, by the FERPA Family Educational Rights and Privacy Act), which for students can be a real and not just theoretical issue due to the risk of stalking, vetting by future employers, surveillance of foreign students by their home nations, etc. Concerns also arise over the use and circulation of intellectual property, both of others and of students themselves. Designing and managing digital instruction with attention to such ethical considerations can be evidence in personnel reviews of the additional teaching effort needed for instructional innovation.
●	In evaluating digital instruction, departments and other campus reviewing agencies should look at course materials and activities in medium-specific ways. But, pragmatically, candidates should also provide reviewers with print-like samplers, especially for difficult to access course materials. As in the case of digital scholarship generally, digital teaching should ideally be evaluated in its original digital or online forms. However, digital teaching materials and outcomes are sometimes difficult to access due to the inability of outsiders to see into a course from a student’s perspective (e.g., in a course management system) or to log into a course’s workspaces and websites. Privacy and other ethical considerations also inhibit opening up course workspaces and forums to outsiders unknown to the students. Therefore, candidates may wish to follow two approaches simultaneously in presenting their teaching. First, they can create guest access for, and curate links to, representative parts of courses that may be seen by outsiders; and, second, they can provide print-like samplers of selected materials, screenshots, etc. that compactly represent essential and representative course elements (omitting or anonymizing materials private to students).
●	Departments and institutions should adjust student course evaluation forms to include ways to assess the digital component in instruction. Similar adjustments should be made if the evaluation procedure includes classroom observation by colleagues or others. Institutions that ask students to fill out course evaluation forms should extend the kinds of questions these forms ask to include an assessment of digital teaching materials and pedagogy. Institutions that conduct course evaluations through classroom observation by colleagues or others should ask evaluators to observe digital materials, activities, and outcomes.
●	In presenting digital instruction for review, candidates (and their departments reporting on the case) should include an overview statement about the added value of the specifically digital in such instruction. Attention should be drawn summatively to how digital teaching enhances or extends the overall learning experience for students.
●	Candidates should emphasize any efforts they made to disseminate digital teaching materials and innovations to colleagues at their institution or to the broader profession. Scholars making innovations in digital instruction often serve as ambassadors, facilitators, and consultants to others interested in such teaching. Sharing teaching resources in a department or to others on campus; posting syllabi, assignments, and tutorials online and bringing it to attention of the profession through social media, blog posts, or discussion groups; and other modes of spreading teaching materials and experiments should be brought to the attention of reviewing committees as an amplifier of a candidate’s teaching effectiveness.
Other Relevant Professional Association Guidelines: 
  Association for Computers and the Humanities,“ACH Guidelines for Assessment of Digital Scholarship in Tenure and Promotion” (2019): 
“Candidate Responsibilities: Make the teaching contribution clear:
* Demonstrate clear goals and learning objectives for incorporating digital media, tools, activities into classroom use;
* Demonstrate the value of courses focused on learning digital methods.”
  Conference on College Composition and Communication, “CCCC Promotion and Tenure Guidelines for Work with Technology” (2015): 
“Online and hybrid courses require significant preparation of digital materials, as well as intensive work on best practices for offering and evaluating online student work. This work can provide key innovations in teaching and student learning, and the additional pedagogical investment and time devoted to preparing these materials should be accounted for in reappointment, tenure, and promotion reviews. If qualified reviewers are not available on the candidate’s home campus, outside reviewers should be asked to provide observations and evaluations of the candidate’s online teaching, e.g., online course management, Massive Open Online Courses (MOOCs), course websites, discussion boards, or blogs.
        Courses offered in the classroom often have substantial and significant online components, such as course websites, electronic portfolios, and blogs, which extend student learning. Candidates who teach in traditional classroom settings, but who employ digital media technologies as a part of their course instruction, should receive assessments of their pedagogical use of digital media as a part of the review of their teaching.”
Useful Resources: 
Digital Pedagogy in the Humanities: Concepts, Models, and Experiments. Home Page. 2020.
Hybrid Pedagogy. Home Page. Hybrid Pedagogy, 2023.
Service
(2.l) Value Digital Service —
Digital scholarship results in additional and new kinds of service that should be recognized in personnel reviews. 
After research and teaching, service is typically the third category of evaluation in personnel reviews, where acknowledged arenas of service can include the department, campus, profession, and community or public. (Some campuses also break out “professional activity” or “professional citizenship” as a fourth evaluation category covering such activities as giving talks, serving on advisory boards, chairing sessions or committees for professional associations, refereeing articles, etc.) The growth of digital scholarship has meant that service involving digital expertise has also greatly expanded, often in ad hoc ways outside standing committees or other recognized service assignments. For this reason, care should be taken to identify and credit any additional service activities of digital scholars.
– Implementation Recommendations –
●	As part of documenting and explaining digital scholarship (see guidelines under 1.c above), candidates should make visible in their review portfolios any additional or new modes of digitally-oriented service. Examples of departmental and campus service by scholars who are early technology adopters include: being asked to manage new curricular programs or specializations in digital humanities, helping design a new department website, assisting colleagues with hybrid teaching or a new course management system, liaising between a department and central campus technology staff, serving on campus or library information technology working groups, supervising a department’s social media accounts, etc. For the profession, examples of service include running or moderating a scholarly list or forum, contributing to an open-source project, etc. For the community or public, examples of service include working on digital public humanities projects with outreach to communities, contributing digital expertise to local educational or cultural organizations, helping local or national activism groups with digital organization and communication, running digital maker workshops for community children, etc. (see also 2.e on public humanities).
●	Departments should establish standing committees or other regularized service roles for digital service to structure and recognize the work of digital scholars in shared governance, administration, and other operations. For example, departments can create a standing “Technology Oversight Committee” or “Digital Scholarship Strategy Committee” to help supervise digital technology development for the department’s faculty, graduate students, and staff. 
Other Relevant Professional Association Guidelines: 
  Conference on College Composition and Communication, “CCCC Promotion and Tenure Guidelines for Work with Technology” (2015): “Department administrators should ensure that the full scope of service performed by candidates who specialize in work with technology and digital media is apparent to the institution’s review committees. While digital media scholarship may be highly visible, digital media service may be less visible to department colleagues as it typically involves solitary work managing department and organizational websites, as well as developing and maintaining listservs, databases, archives, surveys, and online forums.”
Useful Resources:
MLA Commission On Professional Service. “Making Faculty Work Visible: Reinterpreting Professional Service, Teaching, and Research in the Fields of Language and Literature.” Profession, 1996, pp. 161–216. 

3. Additional Guidelines for Faculty and Staff, Departments, Institutions, and Professional Associations
For Faculty and Scholar-Staff
Individual faculty and scholar-staff (including “alternative academic,” “research software engineer,” and other staff performing digital scholarship) should carefully read through the general principles and guidelines in the sections above on “1. Making Digital Scholarship and Its Evaluation Understandable” and “2. Evaluating Digital Research, Teaching, and Service.” These sections take up topics that bear in different ways not just on individual candidates for appointment, promotion, merit increase, or tenure but on their departments and institutions supervising the review process. Seeing the issues from these multiple vantage points helps candidates more fully understand the evaluation process and its implications for digital scholars.
Additionally, faculty and scholar-staff may wish to consider the following specific recommendations for candidates undergoing review:
(3.a) Create a Professional Online Presence —
Faculty and scholar-staff should maintain a professional online presence.
In today’s online era, colleagues in the profession, students considering a university, and others are surprised if they do not see a web page with a scholar’s professional profile. This is even more the case for scholars who work in digital scholarship or on topics related to digital issues and methods, where deep websites are a norm. The indirect impact on personnel reviews of such scholars is that the lack of a well-developed online presence can affect outside reviewers’ and others’ impression of a candidate’s visibility in their field or in the digital scholarship community generally.
– Implementation Recommendations –
●	Digital scholars should create a robust profile for themselves at their institution and/or maintain a professional site on a third-party hosting service. Where possible, a digital scholar’s department or institutional web page should be richly developed with a self-statement and well-presented highlights of current and past research, teaching, and service, plus a c.v. and contact information. In addition, especially if a department’s or institution’s website is standardized in ways that do not allow for custom development, digital scholars should consider creating a website on a third-party hosting service. Many of these allow push-button installation of websites (such as a WordPress installation) and other platforms and services (e.g., custom email accounts, lists, databases, Omeka, Scalar, etc.). Advantages of a third-party site include the ability to host a professional profile and research or teaching materials independently of an institution so that they are portable (which can be especially important for early career and other scholars who anticipate moving to other institutions). Disadvantages include the extra complexity of running a site and the costs of doing so. (Many third-party hosting services have reasonable pricing plans and facilitate purchasing an individualized domain name at nominal annual cost.) Depending on the nature and scale of their digital work, digital scholars may well decide that maintaining their own site is a valuable investment. In addition, digital scholars should create and maintain their profiles on scholarly online networks related to their field and discipline (including, for example, MLA Commons as part of Humanities Commons).
●	Digital scholars should take advantage of digital identifier systems. Increasingly, scholars – and especially digital scholars – benefit from curating their online professional identity through unique digital identifiers (such as ORCID ID’s). They also benefit from assigning digital identifiers to their work when such are not provided through a journal or other venue. Where offered through a service in their campus’s library (or through such services as BibGuru), scholars can create DOIs for any publication, online posting, or other artifact they publish online. Using digital identifiers makes scholars and their work more findable for other scholars and also for search engines, databases, and other aggregators (including those that generate bibliometrics). It also helps such aggregators disambiguate a scholar’s work from that of others with similar names.
Useful Resources:
Honn, Josh. “Creating an Online Scholarly Presence,” Center for Scholarly Communication & Digital Curation. 2014, https://web.archive.org/web/20140205221019/http://cscdc.northwestern.edu/blog/?p=734.
(3.b) Enable Careers for Scholar-Staff —
Staff in “alternative academic,” “research software engineer,” and similar digital scholar-staff positions should ask at time of appointment or reappointment for clarification about institutional support for career development and career progression.
An increasing number of institutions appoint staff with digital scholarship backgrounds for combined administrative, research, instructional, and technical roles embedded (or tied through service arrangements) with departments, centers, labs, libraries, and other units. Titles for such positions related to the digital humanities include DH “director,” “coordinator,” “specialist.” or “librarian.” Titles for related “RSE” research software engineer positions (as they are called especially in Europe, the United Kingdom, and Australasia) include “research software director,” “project manager,” “analyst,” “designer,” or “engineer.” Personnel reviews for such positions can involve input or supervision from the departments with which such specialists are formally or informally affiliated. One of the emerging priorities in digital scholarship is awareness of the need to develop institutional frameworks for supporting the career development and career progression of such scholar-staff. 
– Implementation Recommendations –
●	At time of hiring and reappointment, digital scholars entering scholar-staff positions should ask if their campus as a whole or the specific units in which they will be embedded can offer access to career-development training, career progression support, and other opportunities for professional advancement. Examples of career development opportunities include career mentoring groups and workshops, tuition remission for taking courses on campus, subsidies for conference registration or certification program fees, etc. (See Bethany Nowviskie’s “The #alt-Ac Track,” especially the paragraph on “Professional development opportunities.”)
Useful Resources:
Nowviskie, Bethany. “The #alt-Ac Track: Negotiating Your ‘Alternative Academic’ Appointment.” The Chronicle of Higher Education, 2010.
Nowviskie, Bethany, and Katina Rogers, editors. #alt-Academy: Alternative Academic Careers. MediaCommons, n. d..
Posner, Miriam. “What Alt-Ac Can Do, and What It Can’t.” Miriam Posner’s Blog, 2013.
Smithies, James. “Research Software (RS) Careers: Generic Learnings from King’s Digital Lab,” King’s College London. 2019. Zenodo.
Romanova, Natasha, et al. “Capacity Enhancement in Digital Humanities in the United Kingdom and Ireland: Training and Beyond.” Zenodo, 2021. Zenodo.
(3.c) Make Digital Scholarship Ethical —
Digital scholars in the humanities should familiarize themselves with relevant human-subjects, privacy, intellectual-property, and other ethics protocols (and flag efforts made to comply with protocols as an extra factor of quality in their work).
Scholars in humanities disciplines such as languages and literatures conduct relatively little research, teaching, or service that requires the approval of ethical protocols or special measures to comply with law. And where such protocols and regulations do bear on humanities scholarship – e.g., privacy of student records as governed in the U.S. by the Family Educational Rights and Privacy Act (FERPA) – compliance is either straightforward or assisted by established guidance policies from student affairs offices or other agencies on campus (up to and including as a last resort a campus’s legal counsel). However, because humanities digital scholarship that is online can cross outside the academy to engage in unbuffered ways with society, it potentially confronts scholars with ethical and regulatory issues typically more familiar to scientists and social scientists. These include “human subjects” research constraints as governed by campus Institutional Review Boards (IRB) and state, national, or international regulations concerning digital privacy, data collection and handling, and intellectual property. Research or service that includes a public humanities or community engagement dimension, social media analysis, big data collection from public sources, crowdsourcing, surveying or interviewing, etc.; and teaching that includes posting student work online, asking students to establish public accounts on proprietary or other online platforms, etc. can all be affected. This presents a challenge to digital scholars in the humanities, but a challenge that is also a learning opportunity and a way to bring to notice a further, distinctive mode of quality or excellence in their work.
– Implementation Recommendations –
●	Whenever digital scholars engage in research, teaching, or service that has the potential to raise ethical and regulatory issues, they should do due diligence in learning about relevant safeguard protocols; and they should present such learning and any compliance actions in their personnel reviews as a mark of additional quality in scholarship. Examples of learning include seeking an informal review of a project by a colleague in the social sciences familiar with human subjects protocols, applying for a formal review by a campus’s IRB office, reaching out for consultation from library staff about copyright rulings, and reading relevant policies and guidance documents. Examples of compliance include actually implementing human-subjects protocols approved by an IRB, taking concrete steps to protect student privacy, educating students on intellectual property constraints, etc.
Useful Resources:
Buchanan, Elizabeth A. “Ethics in Digital Research.” Handbuch Soziale Praktiken und Digitale Alltagswelten, edited by Heidrun Friese et al., Springer Fachmedien, 2020, pp. 375–83. Springer Link.
Mertens, Donna M. “Ethics of Qualitative Data Collection.” The SAGE Handbook of Qualitative Data Collection, edited by Uwe Flick, 33–48. Los Angeles, London: SAGE, 2018.
Proferes, Nicholas. “What Ethics Can Offer the Digital Humanities and What the Digital Humanities Can Offer Ethics.” Routledge International Handbook of Research Methods in Digital Humanities, edited by Kristen Schuster and Stuart Dunn, 1st ed., Routledge, 2020, pp. 416–27.
Quinton, Sarah, and Nina Reynolds. “The Changing Roles of Researchers and Participants in Digital and Social Media Research: Ethics Challenges and Forward Directions.” The Ethics of Online Research, edited by Kandy Woodfield, vol. 2, Emerald Publishing Limited, 2017, pp. 53–78.
For Departments (and Programs and Centers)
(3.d) Educate Department Faculty About Digital Scholarship —
Departments unfamiliar with current trends in digital scholarship should take concrete steps to introduce their faculty to the area so that they can responsibly hire and review scholars focused on such work.
Normally, most faculty in language and literature departments are not expected to be familiar with a candidate’s specific domain of expertise (e.g., a particular historical field or other area) when participating in appointment, promotion, merit increase, or tenure evaluations. Steeped in broadly common intellectual traditions and methods (e.g., reading for interpretive analysis), faculty have enough general familiarity with a humanities scholar’s mode of work (kinds of questions asked, theories and approaches brought to bear, kinds of research outputs or course designs produced) to be adequately informed evaluators once they have had a chance to see a sample of writings and listen to a job talk. But the situation of candidates heavily focused on digital scholarship is different due to the extra dimension in their work of digital materials, technologies, methods, media, and forms. New criteria of evaluation – such as whether a digital project meets FAIR principles (of findability, accessibility, interoperability, reusability), conforms to technical standards, is digitally “sustainable,” applies appropriate machine-learning methods, effectively uses content management systems or data-notebooks for teaching, etc., may not be part of the common knowledge of department faculty.
– Implementation Recommendations –
●	Departments and programs that are new at hiring, promoting, or tenuring candidates focused on digital scholarship should prepare by drawing on available expertise on their campus or other resources to introduce their faculty to the current variety and trends of digital research and teaching. This can be accomplished, for example, by holding an all-hands meeting facilitated by a colleague from inside or outside the department familiar with digital scholarship; asking the campus library or another agency to conduct a workshop; bringing in a guest speaker; or organizing a reading group that meets once or twice to discuss selected digital scholarship. It is important that departments not task candidates themselves with providing a basic introduction to digital scholarship during their job talks or other engagements on a campus visit. Though candidates themselves may wish to frame their talks by sketching the landscape of current digital scholarship, they should be given their fair time like any other scholar to present their chosen topic at an advanced level.
Other Relevant Professional Association Guidelines: 
  American Historical Association, “Guidelines for the Professional Evaluation of Digital Scholarship by Historians” (2015): “[Departments] should inform themselves about developments in the digital context of our work. Most colleges and universities have staff in place whose job it is to monitor and promote new technologies. Librarians, in particular, have long been involved in professional conversations regarding new technologies of teaching and scholarship. Many of them will be delighted to hold workshops and address faculty in groups or as individuals.”
Useful Resources:
[TBD]
(3.e) Clarify Expectations If a New Hire Is Expected to Start a Program —
Departments wishing to launch digital humanities (or similar) programs with the help of a new hire should make that expectation explicit.
While digital scholarship has expanded in the profession, relatively few departments have yet normalized such scholarship in departmental and curricular structures – e.g., by designing curricular tracks on digital methods for undergraduates, creating qualifying exam reading lists in the area for graduate students, establishing digital technology planning committees, etc. Departments thus sometimes seek to hire in the digital humanities – or in any field but with a “plus” of digital humanities on the side – on the assumption that the hire will start and supervise a digital program, curricular track, or other initiative. Such goals can be excellent for both the department and the new hire, so long as they are clarified and appropriate protections put in place for the candidate (such as course relief or relief from other service in recognition of the administrative work involved).
– Implementation Recommendations –
●	Job ads and letters of offer to digital scholars should be forthright about whether, and when, departments expect a candidate to lead or participate in designing, founding, and managing digital research, teaching, or service initiatives for the department. This is especially important when a department is hiring an early career scholar who is not yet tenured and for whom arrangements of relief from other duties need to be made to allow their careers to develop.
Other Relevant Professional Association Guidelines: 
  
Useful Resources:

(3.f) Frame Humanities Digital Scholarship in Relation to Digital Scholarship in Other Disciplines —
In presenting the personnel cases of digital scholars to higher-level campus reviewing agencies, departments should both compare and contrast humanities digital scholarship to digital work in other disciplines.
Strong and valid arguments can be made about the convergence of digital materials, methods, tools, forms, and media in the humanities with digital work in the sciences and social sciences. Interdisciplinary convergence is one of the most exciting aspects of digital scholarship. But equally important arguments can be made about differences in the assumptions, questions, and intellectual traditions of humanities digital work. Differences include the fact that humanities “datasets” can be much smaller than scientific ones and include many more missing, mismatched, or otherwise “messy” data due to historical provenance; that the purpose of modeling data in the humanities may be exploration rather than confirmation or prediction; and that attention to the media-specificity of technologies can be especially important in language and literature fields as an extension (at once similar and different) of key formalist aesthetic traditions in the twentieth century.
– Implementation Recommendations –
●	In writing up the personnel cases of digital scholars for higher-level reviewing agencies and deans, departments should where appropriate point out the special goals and features of the humanities that distinguish humanities digital work. Just as humanities chairs have been used to explaining to reviewing committees why humanities books are important and take so long to write compared to scientific articles or conference proceedings, so they should explain that the purpose (for example) of data collection, machine learning, tool building, and other digital work in the humanities overlaps with that of the sciences and social sciences but also differs according to humanistic epistemic values of exploratory, critical, and creative reading and writing.
Other Relevant Professional Association Guidelines: 
  
Useful Resources:
Ramsay, Stephen. “Algorithmic Criticism.” A Companion to Digital Literary Studies, Blackwell, 2008, pp. 477–91.
__________. Reading Machines: Toward an Algorithmic Criticism. University of Illinois Press, 2011.
For Institutions (Universities & Colleges)
(3.g) Encourage Interdisciplinary Understanding of Digital Scholarship —
Institutions should take concrete steps to encourage disciplines to discover similarities and differences in digital scholarship. 
Encouraging interdisciplinary understanding of digital scholarship would especially benefit universities and colleges starting a hiring initiative to expand computer science, information science, data science, digital social science, digital humanities, and/or digital arts initiatives across campus. To advance cross-divisional collaboration between such fields, promote interdisciplinary research (and grants), seed interdisciplinary curricular initiatives and new “general education” courses, and also – specifically relevant to personnel reviews – to establish common expectations about “what is good digital scholarship?”, institutions should create opportunities to bring faculty and administrators together to share understandings of digital work. Such opportunities can take many forms (e.g., workshops, summit meetings, conferences, etc.); and they can be timed at “big bang” institutional moments such as the beginning of a hiring initiative or the launch of a new data science program.
– Implementation Recommendations –
●	Institutions should ask their schools, divisions, departments, programs, centers, or other units with a stake in digital scholarship to organize one or more institution-wide event. As an example, many institutions have recently started or are in the process of building schools, departments, programs, centers, and majors in data science and artificial intelligence. Each of these topics requires core expertise in computer science, information science, and statistics; but each also intersects with many other fields (as indicated in the way data science programs, for instance, often require majors to choose among “domain emphases” that include fields in the social sciences or humanities and arts). Schools, departments, and programs arising around these topics have a need to grow in cross-cutting disciplinary ways. They would thus serve as excellent hosts for all-campus convenings on the question, “what is good digital scholarship?”
●	Institutions should create opportunities for campus units involved in disciplinary scholarship to converse with other sectors of society that also have an interdisciplinary stake in digital work. Though it would have to be done carefully, institutions should find ways to invite leaders and experts from the technology industry, journalism, government, NGOs, and others working with digital methods, media, and information to participate in all-campus conversations about “what is good digital scholarship?” (perhaps with the question widened to “knowledge” instead of “scholarship”).
Other Relevant Professional Association Guidelines: 
  
Useful Resources:
[TBD]
For Professional Associations, Learned Societies, and Organizations in the Humanities and Digital Humanities
(3.h) Create Repositories of Resources —
Associations, societies, and organizations in the humanities (and digital humanities) should maintain repositories of resources, including templates and examples, to assist in documenting and evaluating digital scholarship. 
One of the hallmarks of earlier guidelines for the evaluation of digital scholarship by professional associations such as the MLA (which issued version 2.0 of these “Guidelines” in 2012), American Historical Association, and Association for Computers and the Humanities is that they ask both candidates and their departments to take responsibility for inventing ways to document and explain digital scholarship. Everyone was expected to reinvent the wheel. Now that the profession has had longer experience with digital scholarship, it would be useful for associations, societies, and organizations in the humanities – ideally, a consortium acting collaboratively – to create a repository of templates, examples, and other resources that can be adapted by candidates and departments engaged in personnel reviews. A precedent in the sciences is the “Package of Measures to Support a Shift in the Culture of Research Assessment” created by the German Research Foundation (DFG) in 2022, which includes a standard template for c.v.’s.
– Implementation Recommendations –
●	Professional associations, learned societies, or organizations for the humanities (and digital humanities) should individually or in concert create an open repository of templates and exemplary materials to assist in personnel cases for digital scholars. For instance, the repository might hold anonymized or hypothetical versions of candidate c.v.’s, self-statements, and review portfolios; and department job ads, job offer letters, letters soliciting referees, and reports on cases; etc.
●	The repository should be “evergreen” and subject to review and revision at set intervals of years.
●	Eventually, the repository should be implemented in a digital format (e.g., TEI and  “linked data”) with a common taxonomy allowing for the development of a federated resource that different humanities groups can contribute to and draw from.
●	As part of such a repository, guidelines issued by professional associations for evaluating digital scholarship (such as these MLA guidelines themselves) should be implemented in machine-readable form (e.g., TEI and “linked data”) with a common taxonomy. The reason is that there are an increasing number of such guidelines from different groups, and they would benefit from the FAIR principles of machine finability, accessibility, interoperability, and reusability.
●	For sustainability, materials and guidelines for evaluating digital scholarship developed by professional associations and organizations should be deposited in a “TRUST” digital repository or equivalent. This recommendation actually applies in general to all publications and reports from associations such as the MLA, which would benefit from deposits in appropriate digital repositories not only for sustainability but also for versioning and FAIR findability, accessibility, interoperability, and reusability.
Other Relevant Professional Association Guidelines: 
  
Useful Resources:
Deutsche Forschungsgemeinschaft (DFG). “Package of Measures to Support a Shift in the Culture of Research Assessment.” Information for Researchers, vol. 61, no. 1 September 2022, 2022, https://www.dfg.de/en/research_funding/announcements_proposals/2022/info_wissenschaft_22_61/index.html.
(3.i) Create a Protocol for Citing Collaborative Work —
Professional associations, societies, and organizations in the humanities (and digital humanities) should coordinate on developing a shared protocol for citing and crediting collaborative scholarship. 
(See also 2.d on recognizing collaboration.)
– Implementation Recommendations –
●	Associations such as the MLA, American Historical Association, the College Art Association, the Conference on College Composition and Communication (CCCC) Committee on Computers and Composition, etc.) – as well as digital humanities-related organizations such as ADHO (Alliance of Digital Humanities Organizations) and ELO (Electronic Literature Organization) – should develop a shared vocabulary of roles and relations in collaborative work that can be used to create citations and credit statements adequate to the complexity of collaborative digital projects and to today’s ethos of inclusive acknowledgement. This could start as a project that surveys the associations’ membership for varieties of collaborative roles and activities. The ultimate result might be a formal taxonomy implemented in machine-readable form using protocols such as OWL Web ontology language, RDF (Resource Description Framework),TEI prosopography guidelines, and CSL (Citation Style Language).
Other Relevant Professional Association Guidelines: 
  
Useful Resources:
Lowry, Paul B., et al. “Building a Taxonomy and Nomenclature of Collaborative Writing to Improve Interdisciplinary Research and Practice.” Journal of Business Communication, vol. 41, no. 1, 2004, pp. 66–99. 
(3.j) Conduct Workshops on Personnel Review —
Professional associations and organizations should organize activities to assist candidates and chairs in preparing personnel cases involving digital scholarship.
Such activities might also include conversations with publishers, journal editors, and others in scholarly communication whose digital platforms and protocols for publication, refereeing, citation, and bibliometrics co-evolve with the research, teaching, and service activities of digital scholars.
– Implementation Recommendations –
●	Associations such as the MLA (perhaps in league with sibling associations in the humanities such as the American Historical Association, the College Art Association, the Conference on College Composition and Communication (CCCC) Committee on Computers and Composition, etc.) should conduct workshops on the evaluation of digital scholarship. If held virtually in the fall, such workshops would coincide with the season when personnel cases are often prepared. If held at the MLA convention in January, panelists and the audience might be widened to include publishers and editors engaged in new ways of publishing, refereeing and, promoting digital scholarship.
Other Relevant Professional Association Guidelines: 
  
Useful Resources:
[TBD]

Credits & Acknowledgements
Version 3 of the MLA’s “Guidelines for Evaluating Digital Scholarship” was created by the MLA Committee on Information Technology (CIT) over two years (2022-24) of the committee’s membership:
●	Eduard Arriaga (Clark U.)
●	Elisa Beshero-Bondar (Pennsylvania State U., Behrend)
●	Lee Skallerup Bessette (Georgetown U., chair 2021-22)
●	Alan Liu (UC Santa Barbara; CIT chair 2022-23)
●	Élika Ortega (U. Colorado, Boulder)
●	Lynn Ramey (Vanderbilt U.)
●	Nhora Lucía Serrano (Hamilton C.; CIT chair 2023-24)
●	Avery J. Wiscomb (Virginia Tech U.)
●	Iva Youkilis (Washington U., St. Louis)
●	Brenda Jo Brueggemann (U. Connecticut, Storrs; CIT liaison to the MLA Executive Council)
Members of the MLA staff who assisted include:
●	Paula M. Krebs (MLA Executive Director)
●	Alenda S. A. Chang ("Director of Outreach; Head of Communications; Managing Editor, Profession)
●	Leigh A. Neithardt (Coordinator of Governance and Assistant to the Executive Director)
●	Anne Donlon (CIT staff liaison, and MLA Technical Project Manager)
●	Thanh Trinh (CIT Staff Liaison, and MLA Director of Information Systems and Chief Information Officer)
The Committee on Information Technology requested consultation from many professional associations, organizations, and other MLA committees.Thanks especially to the following groups, which offered particularly helpful suggestions. (The CIT is grateful to specific leaders and staff acting as representatives of these groups, though acknowledgement of them here is subsumed in credits to their groups.)
●	Alliance of Digital Humanities Organizations (ADHO)
●	American Historical Association
●	College Art Association (CAA)
●	Council of Editors of Learned Journals (CELJ)
●	Advanced Research Consortium (ARC) and NINES Networked Infrastructure for Nineteenth-Century Electronic Scholarship
The CIT additionally acknowledges the following individual experts for suggestions and references to resources:
●	James Smithies (King’s College)
●	John Unsworth (U. Virginia)
●	[Others TBD]

Works Cited
Works mentioned in these guidelines are linked to current online versions where they exist. Also included in the Works Cited list below are links under the label “[archived copy]” to permanent archived versions in the Internet Archive, “trust” digital repositories, or elsewhere. (However, archival links are omitted for works already linked from trust repositories or when no known permanent copy exists or is allowed to be created by third parties.)
●	Adema, Janneke. “Living Books: Experiments in the Posthumanities.” MIT Press, 2021. direct.mit.edu, https://doi.org/10.7551/mitpress/11297.001.0001. [archived copy] 
●	ALLEA (European Federation of Academies of Sciences and Humanities) E-Humanities Working Group. “ALLEA E-Humanities Working Group Draft Report on Digital Scholarly Outputs [OPEN CONSULTATIONS].” Google Docs, 2023, https://docs.google.com/document/d/1vEHPJD8WOyizWHQeoOUUrlDYgOM7Y62ahZ83IeL_bOY/edit?usp=embed_facebook. [archived copy TBD] 
●	ALLEA (European Federation of Academies of Sciences and Humanities) Working Group E-Humanities. “Sustainable and FAIR Data Sharing in the Humanities: Recommendations of the ALLEA Working Group E-Humanities.” ALLEA, 2020, https://doi.org/10.7486/DRI.tq582c863. Digital Repository of Ireland. 
●	American Academy of Religion. “Guidelines for Evaluating Digital Scholarship.” 2018, https://aarweb.org/AARMBR/AARMBR/About-AAR-/Board-of-Directors-/Board-Resolutions-/Guidelines-for-Evaluating-Digital-Scholarship.aspx. [archived copy]
●	American Historical Association, “Guidelines for the Professional Evaluation of Digital Scholarship by Historians.” 2015, https://www.historians.org/teaching-and-learning/digital-history-resources/evaluation-of-digital-scholarship-in-history/guidelines-for-the-professional-evaluation-of-digital-scholarship-by-historians. [archived copy]
●	American Historical Association. “Working Group Issues Tenure, Promotion, and the Publicly Engaged Academic Historian Report.” Perspectives on History: Newsmagazine of the American Historical Association, 2010, https://www.historians.org/research-and-publications/perspectives-on-history/september-2010/working-group-issues-tenure-promotion-and-the-publicly-engaged-academic-historian-report. [archived copy]
●	Association for Computers and the Humanities. ACH Guidelines for Assessment of Digital Scholarship in Tenure and Promotion. 2019, https://ach.org/blog/2019/08/05/ach-guidelines-for-assessment-of-digital-scholarship-in-tenure-and-promotion/. [archived copy] 
●	Bates, David, et al. Peer Review and Evaluation of Digital Resources for the Arts and Humanities Final Report. School of Advanced Study, University of London, 2006, https://sas-space.sas.ac.uk/51/. [archived copy]  
●	Borek, Luise, et al. TaDiRAH: Taxonomy of Digital Research Activities in the Humanities (version 2.0). 2020, https://vocabs.dariah.eu/tadirah/en/. [archival copy]
●	Bradley, Kevin. “Defining Digital Sustainability.” Library Trends, vol. 56, no. 1, 2007, pp. 148–63. muse.jhu.edu, https://doi.org/10.1353/lib.2007.0044.  [archival copy] 
●	Broadberry, Laura. “How to Use Altmetrics to Showcase Engagement Efforts for Promotion and Tenure.” Altmetric, 2016, https://www.altmetric.com/blog/how-to-use-altmetrics-to-showcase-engagement-efforts-for-promotion-and-tenure/. [archived copy] 
●	Buchanan, Elizabeth A. “Ethics in Digital Research.” Handbuch Soziale Praktiken und Digitale Alltagswelten, edited by Heidrun Friese et al., Springer Fachmedien, 2020, pp. 375–83. Springer Link, https://doi.org/10.1007/978-3-658-08357-1_47. [archived copy]  
●	Ciula, Arianna. “KDL Checklist for Digital Outputs Assessment.” King’s College, 2019. Zenodo, Zenodo, https://doi.org/10.5281/zenodo.3361580.
●	Clement, Tanya E., et al. “Collaborators’ Bill of Rights.” Digital Pedagogy in the Humanities, 2021. Humanities Commons. https://hcommons.org/deposits/item/hc:31187/. [archival copy]
●	College Art Association and the Society of Architectural Historians. “Guidelines for the Evaluation of Digital Scholarship in Art and Architectural History.” 2016, http://www.collegeart.org/pdf/evaluating-digital-scholarship-in-art-and-architectural-history.pdf. [archived copy]
●	Conference on College Composition and Communication (CCCC). “Statement of Professional Guidance for New Faculty Members.” 2022, https://cccc.ncte.org/cccc/resources/positions/professionalguidance/. [archived copy]
●	Conference on College Composition and Communication (CCCC) Committee on Computers and Composition. “CCCC Promotion and Tenure Guidelines for Work with Technology.” 2015, https://cccc.ncte.org/cccc/resources/positions/promotionandtenure. [archived copy] 
●	Deutsche Forschungsgemeinschaft (DFG). “Package of Measures to Support a Shift in the Culture of Research Assessment.” Information for Researchers, vol. 61, no. 1 September 2022, 2022, https://www.dfg.de/en/research_funding/announcements_proposals/2022/info_wissenschaft_22_61/index.html. [archived copy] 
●	Digital Pedagogy in the Humanities: Concepts, Models, and Experiments. Home Page. 2020, https://digitalpedagogy.hcommons.org/. [archived copy] 
●	Electronic Literature Directory. Home Page. n. d., https://directory.eliterature.org/. [archived copy] 
●	Electronic Literature Knowledge Base (ELMCIP). Home Page. n. d., https://elmcip.net/. [archived copy] 
●	Fair Cite. Home Page. Fair Cite, 2012, https://faircite.wordpress.com/. [archived copy] 
●	Few, Stephen. “Eenie, Meenie, Minie, Moe: Selecting the Right Graph for Your Message.” Perceptual Edge, 2004, http://www.perceptualedge.com/articles/ie/the_right_graph.pdf. [archived copy] 
●	Gebru, Timnit, et al. “Datasheets for Datasets.” ArXiv:1803.09010 [Cs], 2019. arXiv.org, http://arxiv.org/abs/1803.09010. [archived copy]  
●	Global Indigenous Data Alliance (GIDA). “CARE Principles.” Global Indigenous Data Alliance, 2022, https://www.gida-global.org/care. [archived copy]
●	GOFAIR. “FAIR Principles.” GO FAIR, n. d., https://www.go-fair.org/fair-principles/. [archived copy]
●	Gould, Amanda Starling. “A Bibliographic Overview of Electronic Literature.” Electronic Literature Directory, 2012, https://directory.eliterature.org/article/4573. [archived copy] 
●	Grootveld, Marjan, and Gültekin Gürdal. “OpenAIRE Guide on How to Find a Trustworthy Repository for Your Data.” 2018. Zenodo, https://doi.org/10.5281/zenodo.4077212.
●	Hayles, N. Katherine. “Electronic Literature: What Is It?” Electronic Literature Organization, 2007, https://eliterature.org/pad/elp.html. [archived copy] 
●	Hicks, Diana, et al. “The Leiden Manifesto for Research Metrics.” Nature, vol. 520, no. 7548, 2015, pp. 429–31. www.nature.com, https://doi.org/10.1038/520429a. [archived copy TBD]
●	Honn, Josh. “Creating an Online Scholarly Presence,” Center for Scholarly Communication & Digital Curation. 2014, https://web.archive.org/web/20140205221019/http://cscdc.northwestern.edu/blog/?p=734.  
●	Hybrid Pedagogy. Home Page. Hybrid Pedagogy, 2023, https://hybridpedagogy.org/. [archived copy]  
●	Lin, Dawei, et al. “The TRUST Principles for Digital Repositories.” Scientific Data, vol. 7, no. 1, May 2020, p. 144. www.nature.com, https://doi.org/10.1038/s41597-020-0486-7. [archived copy]  
●	Liu, Alan, et al. Research + Activism Bibliography. 2022, https://rab.english.ucsb.edu/.  [archived copy TBD] 
●	Lowry, Paul B., et al. “Building a Taxonomy and Nomenclature of Collaborative Writing to Improve Interdisciplinary Research and Practice.” Journal of Business Communication, vol. 41, no. 1, 2004, pp. 66–99. https://doi.org/10.1177/0021943603259363. [archived copy]  
●	McClurken, Jeffrey. “Digital History Reviews (Journal of American History).” Organization of American Historians, 2013, http://jah.oah.org/submit/digital-history-reviews/. [archived copy] 
●	Mertens, Donna M. “Ethics of Qualitative Data Collection.” The SAGE Handbook of Qualitative Data Collection, edited by Uwe Flick, 33–48. Los Angeles, London: SAGE, 2018,  https://methods.sagepub.com/book/the-sage-handbook-of-qualitative-data-collection/i487.xml. [archived copy]  
●	Modern Language Association Committee on Academic Freedom and Professional Rights and Responsibilities. “Advice for Authors, Reviewers, Publishers, and Editors of Literary Scholarship.” Modern Language Association, 2016, https://www.mla.org/Resources/Guidelines-and-Data/Reports-and-Professional-Guidelines/Advice-for-Authors-Reviewers-Publishers-and-Editors-of-Literary-Scholarship. [archived copy]  
●	Modern Language Association, “Guidelines for Evaluating Digital Scholarship.” Modern Language Association,
○	Version 3.0 (2024) [archived copy TBD]
○	Version 2.0: “Guidelines for Evaluating Work in Digital Humanities and Digital Media.” Modern Language Association, 2012. [archived copy]
●	________. “Guidelines for Evaluating Publicly Engaged Humanities Scholarship in Language and Literature Programs.” Modern Language Association, 2022, https://www.mla.org/Resources/Guidelines-and-Data/Reports-and-Professional-Guidelines/Guidelines-for-Evaluating-Publicly-Engaged-Humanities-Scholarship-in-Language-and-Literature-Programs. [archived copy] 
●	________. “Guidelines for Information Technology Access and Support for the Modern Languages.” Modern Language Association, 2012, https://www.mla.org/About-Us/Governance/Committees/Committee-Listings/Professional-Issues/Committee-on-Information-Technology/Guidelines-for-Information-Technology-Access-and-Support-for-the-Modern-Languages. [archived copy]
●	________. “Report of the MLA Task Force on Evaluating Scholarship for Tenure and Promotion.” [See under Stanton, Domna C., et al.]
●	________, Commission On Professional Service. “Making Faculty Work Visible: Reinterpreting Professional Service, Teaching, and Research in the Fields of Language and Literature.” Profession, 1996, pp. 161–216, https://www.jstor.org/stable/25595594. [archived copy] 
●	Modern Language Association Committee on Academic Freedom and Professional Rights and Responsibilities. “Advice for Authors, Reviewers, Publishers, and Editors of Literary Scholarship.” Modern Language Association, 2016, https://www.mla.org/Resources/Guidelines-and-Data/Reports-and-Professional-Guidelines/Advice-for-Authors-Reviewers-Publishers-and-Editors-of-Literary-Scholarship. [archived copy] 
●	Nowviskie, Bethany. “The #alt-Ac Track: Negotiating Your ‘Alternative Academic’ Appointment.” The Chronicle of Higher Education, 2010, https://www.chronicle.com/blogs/profhacker/the-alt-ac-track-negotiating-your-alternative-academic-appointment-2. 
●	Nowviskie, Bethany. “Where Credit Is Due: Preconditions for the Evaluation of Collaborative Digital Scholarship.” Profession, 2011, pp. 169–81. https://www.jstor.org/stable/41714117. [archived copy] 
●	Nowviskie, Bethany, and Katina Rogers, editors. #alt-Academy: Alternative Academic Careers. MediaCommons, n. d., http://mediacommons.org/alt-ac/. [archived copy] 
●	Posner, Miriam. “What Alt-Ac Can Do, and What It Can’t.” Miriam Posner’s Blog, 2013, https://miriamposner.com/blog/what-alt-ac-can-do-and-what-it-cant/. [archived copy] 
●	Priem, J., et al. “Altmetrics: A Manifesto.” Altmetrics, 2010, http://altmetrics.org/manifesto/. [archived copy] 
●	Proferes, Nicholas. “What Ethics Can Offer the Digital Humanities and What the Digital Humanities Can Offer Ethics.” Routledge International Handbook of Research Methods in Digital Humanities, edited by Kristen Schuster and Stuart Dunn, 1st ed., Routledge, 2020, pp. 416–27. DOI.org (Crossref), https://doi.org/10.4324/9780429777028-29. [archived copy] 
●	Quinton, Sarah, and Nina Reynolds. “The Changing Roles of Researchers and Participants in Digital and Social Media Research: Ethics Challenges and Forward Directions.” The Ethics of Online Research, edited by Kandy Woodfield, vol. 2, Emerald Publishing Limited, 2017, pp. 53–78. Emerald Insight, https://doi.org/10.1108/S2398-601820180000002003. [archived copy] 
●	Ramsay, Stephen. “Algorithmic Criticism.” A Companion to Digital Literary Studies, Blackwell, 2008, pp. 477–91, https://companions.digitalhumanities.org/DLS/?chapter=content/9781405148641_chapter_26.html. [archived copy]  
●	__________. Reading Machines: Toward an Algorithmic Criticism. University of Illinois Press, 2011, https://onlinelibrary.wiley.com/doi/epdf/10.1002/9781405177504.ch26. [archived copy]  
●	Risam, Roopika. “Stewarding Place: Digital Humanities at the Regional Comprehensive University.” People, Practice, Power: Digital Humanities Outside the Center, Debates in the Digital Humanities, U. Minnesota Press, 2021, https://dhdebates.gc.cuny.edu/read/people-practice-power/section/ec8c6e52-0619-4879-a65a-7aa2edb377ed. [archived copy] 
●	Rockwell, Geoffrey. “On the Evaluation of Digital Media as Scholarship.” Profession, 2011, pp. 152–68, https://www.jstor.org/stable/41714116. 
●	Romanova, Natasha, et al. “Capacity Enhancement in Digital Humanities in the United Kingdom and Ireland: Training and Beyond.” Zenodo, 2021. Zenodo, https://zenodo.org/record/5105938. 
●	Segel, Edward, and Jeffrey Heer. “Narrative Visualization: Telling Stories with Data.” IEEE Transactions on Visualization and Computer Graphics, vol. 16, no. 6, 2010, pp. 1139–48. November 2010, https://doi.org/10.1109/TVCG.2010.179. [archived copy]  
●	Shanahan, Daniel R. “A Living Document: Reincarnating the Research Article.” Trials, vol. 16, no. 1, Apr. 2015, p. 151. Springer Link, https://doi.org/10.1186/s13063-015-0666-5. [archived copy] 
●	Smithies, James. “Research Software (RS) Careers: Generic Learnings from King’s Digital Lab,” King’s College London. 2019. Zenodo, https://doi.org/10.5281/zenodo.2564790. 
●	Stanton, Domna C., et al. “Report of the MLA Task Force on Evaluating Scholarship for Tenure and Promotion.” Profession, 2007, pp. 9–71, https://www.jstor.org/stable/25595848. [archived copy]
●	TEI Text Encoding Initiative. Text Encoding Initiative (TEI) Guidelines. 2023, https://tei-c.org/guidelines/. [archived copy] 
